{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iiDzBoKGwmMZ"
   },
   "source": [
    "# REDES NEURONALES\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "En esta actividad vamos a utilizar una red neuronal para clasificar imágenes de dígitos del 0 al 9 escritos a mano. Para ello, utilizaremos Keras con TensorFlow.\n",
    "\n",
    "El dataset a utilizar es MNIST, una base de datos constituida por (como no) imágenes de dígitos escritos a mano. Este dataset es ampliamente utilizado en docencia como punto de entrada al entrenamiento de redes neuronales y otros, pero también es muy utilizado en trabajos reales de investigación para el entrenamiento de imágenes. Puedes consultar más información sobre el dataset en [este enlace](https://es.wikipedia.org/wiki/Base_de_datos_MNIST).\n",
    "\n",
    "El código utilizado para contestar tiene que quedar claramente reflejado en el Notebook. Puedes crear nuevas celdas si así lo deseas para estructurar tu código y sus salidas. A la hora de entregar el notebook, **asegúrate de que los resultados de ejecutar tu código han quedado guardados y que son perfectamente visibles en la versión PDF que debes entregar adjunta**. Por ejemplo, a la hora de entrenar una red neuronal tiene que verse claramente un log de los resultados de cada epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install keras\n",
    "#!pip install tensorflow\n",
    "#!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "gSHr268SwmMa"
   },
   "outputs": [],
   "source": [
    "from keras.datasets.mnist import load_data\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zScMKU2OKSPD"
   },
   "source": [
    "Tenemos la suerte de que el dataset MNIST, el que vamos a utilizar en esta actividad, está guardado en Keras, por lo que podemos utilizarlo sin necesidad de buscar el dataset de forma externa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "4voG2hxxG4h3"
   },
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.fashion_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JphLsCvgKrzb"
   },
   "source": [
    "Llamar a **load_data** en este dataset nos dará dos conjuntos de dos listas, estos serán los valores de entrenamiento y prueba para los gráficos que contienen los dígitos y sus etiquetas.\n",
    "\n",
    "Nota: Aunque en esta actividad lo veis de esta forma, también lo vais a poder encontrar como 4 variables de esta forma: training_images, training_labels, test_images, test_labels = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "1muD4PHEG4h6"
   },
   "outputs": [],
   "source": [
    "(training_images, training_labels), (test_images, test_labels) = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZWGpJqVVLT3Y"
   },
   "source": [
    "Antes de continuar vamos a dar un vistazo a nuestro dataset, para ello vamos a ver una imagen de entrenamiento y su etiqueta o clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 933
    },
    "id": "t5a5PlswG4h8",
    "outputId": "962a9313-a7c9-44bd-d6bd-e7b25669e913"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136 175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253 225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251  93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119  25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253 150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252 253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249 253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253 253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253 250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201  78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(linewidth=200)\n",
    "plt.imshow(training_images[0], cmap=\"gray\") # recordad que siempre es preferible trabajar en blanco y negro\n",
    "#\n",
    "print(training_labels[0])\n",
    "print(training_images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BaqXlSMBwmMg"
   },
   "source": [
    "## 1. Información sobre el dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e0aer8ZZwmMh"
   },
   "source": [
    "Una vez tenemos los datos cargados en memoria, vamos a obtener información sobre los mismos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E-im9PnEwmMh"
   },
   "source": [
    "**Pregunta 1.1 *(0.25 puntos)*** ¿Cuántas imágenes hay de *training* y de *test*? ¿Qué tamaño tienen las imágenes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "lvP0Y4SCwmMi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensión del dataset de entrenamiento: (60000, 28, 28)\n",
      "Dimensión del dataset de prueba: (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Voy a cambiar las variables por nomeclatura\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = (training_images, training_labels), (test_images, test_labels)\n",
    "# Mostrar información del conjunto\n",
    "print(\"Dimensión del dataset de entrenamiento:\", x_train.shape)\n",
    "print(\"Dimensión del dataset de prueba:\", x_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xwp5ljFKwmMj"
   },
   "source": [
    "El número de imágenes de entrenamiento es de 60000 y el número de imágenes de prueba es de 10000. La dimensión de las imágenes es de 28x28 px."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F2LsvfHOwmMk"
   },
   "source": [
    "**Pregunta 1.2 *(0.25 puntos)*** Realizar una exploración de las variables que contienen los datos. Describir en qué consiste un example del dataset (qué información se guarda en cada imagen) y describir qué contiene la información en y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3W5rzaGxwmMk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipo de x_train: uint8\n",
      "Tipo de y_train: uint8\n",
      "Etiquetas únicas: [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "# Ver tipos de datos\n",
    "print(\"Tipo de x_train:\", x_train.dtype)\n",
    "print(\"Tipo de y_train:\", y_train.dtype)\n",
    "\n",
    "# Valores únicos en las etiquetas\n",
    "print(\"Etiquetas únicas:\", np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizar alguna imágenes con sus etiquetas\n",
    "plt.imshow(x_train[0], cmap='gray')\n",
    "plt.title(f\"Etiqueta: {y_train[0]}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zaEWKFyvwmMm"
   },
   "source": [
    "La variable x_train contiene imágenes en escala de grises de tamaño 28x28 píxeles, cada una representada como una matriz de valores entre 0 y 255 (intensidad de gris). Cada elemento en x_train es una imagen de un dígito escrito a mano.\n",
    "\n",
    "Por ejemplo, x_train[0] es una matriz de 28x28 que representa la intensidad de cada píxel de la primera imagen del conjunto de entrenamiento.\n",
    "\n",
    "La variable y_train contiene las etiquetas correspondientes a cada imagen. Es un vector de enteros del 0 al 9, donde cada número indica el dígito que aparece en la imagen correspondiente. Por ejemplo, si y_train[0] = 5, significa que la imagen x_train[0] representa un 5 escrito a mano."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OXWLSFdnwAay"
   },
   "source": [
    "## 2. Normalización y preprocesado de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H9W9mgi7wUOY"
   },
   "source": [
    "**Pregunta 2.1 (0.25 puntos)** Habreis notado que todos los valores numericos están entre 0 y 255. Si estamos entrenando una red neuronal, una buena practica es transformar todos los valores entre 0 y 1, un proceso llamado \"normalización\" y afortunadamente en Python es fácil normalizar una lista. ¿Cómo lo podemos hacer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "n-BhUak6wjGc"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Normalización: escalar los píxeles al rango [0, 1].\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test = x_test.astype(\"float32\") / 255.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es conveniente escalar las entradas al rango [0,1] porque mejora la eficiencia y estabilidad del proceso de entrenamiento de la red neuronal. La normalización reduce la varianza de los datos y evita que los valores de entrada grandes dominen los gradientes durante el entrenamiento, lo que podría ralentizar o incluso impedir la convergencia.\n",
    "\n",
    "Además, muchas funciones de activación como sigmoid o tanh son sensibles a la escala de los datos. Si las entradas no están normalizadas, estas funciones pueden saturarse (producir gradientes cercanos a cero), lo que complica el aprendizaje."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aAj9bKbJxDoN"
   },
   "source": [
    "**Pregunta 2.2 (0.25 puntos)** Utiliza la función ***reshape*** de Numpy para convertir las imágenes en vectores de características de un tamaño de (N, 784). Explica con tus palabras por qué es necesario hacer esto.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "qRdZBcCKxvLZ"
   },
   "outputs": [],
   "source": [
    "# Reestructuración: aplanar las imágenes 28x28 a vectores de 784 elementos\n",
    "x_train = x_train.reshape(-1, 28 * 28)\n",
    "x_test = x_test.reshape(-1, 28 * 28)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LCIZJRjWxwrE"
   },
   "source": [
    "**Respuesta a la pregunta 2.2**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buscando información, resulta que el reshape es necesario porque las redes neuronales densas requieren vectores como entrada, no matrices. Las imágenes originales de 28x28 píxeles deben aplanarse en vectores de 784 elementos para que puedan ser procesadas por las capas densas de la red. Esta transformación mantiene toda la información de los píxeles, pero cambia su forma para que sea compatible con la arquitectura del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El uso de -1 en reshape(-1, 784) no es obligatorio, pero es muy conveniente. Permite a la función calcular automáticamente la cantidad de ejemplos en el conjunto de datos. Esto hace el código más general y evita errores si cambia el tamaño del conjunto (como al usar diferentes particiones o subconjuntos). Es una práctica recomendada para mantener el código más limpio y flexible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VUJ9BpFSyR3m"
   },
   "source": [
    "**Pregunta 2.3 (0.25 puntos)** Para facilitar el desarrollo de la actividad, vamos a expresar las etiquetas así:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "jwgU9vScyZy_"
   },
   "outputs": [],
   "source": [
    "training_labels = tf.keras.utils.to_categorical(training_labels)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "itJBwG0Lyy2u"
   },
   "source": [
    "Muestra cómo son ahora los datos, como resultado de este cambio y también de los realizados en las dos preguntas anteriores. Debate cómo se beneficiará la red neuronal de todos estos cambios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "J0h1cc3CzJfs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etiqueta original: 5\n",
      "Etiqueta codificada (one-hot): [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "Forma de y_train después del one-hot encoding: (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Ejemplo antes de la codificación\n",
    "print(\"Etiqueta original:\", y_train[0])  # numérica\n",
    "\n",
    "# Codificación one-hot (ya hecho antes, repetimos para claridad)\n",
    "y_train_encoded = to_categorical(y_train)\n",
    "y_test_encoded = to_categorical(y_test)\n",
    "\n",
    "# Ejemplo después de la codificación\n",
    "print(\"Etiqueta codificada (one-hot):\", y_train_encoded[0])\n",
    "\n",
    "# Mostrar la forma de los datos\n",
    "print(\"Forma de y_train después del one-hot encoding:\", y_train_encoded.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GsG0MKk9zKsU"
   },
   "source": [
    "**Respuesta a la pregunta 2.3:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras aplicar to_categorical, las etiquetas han pasado de ser valores enteros entre 0 y 9 (por ejemplo, 5) a vectores binarios de 10 posiciones (por ejemplo, [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]).\n",
    "\n",
    "Este cambio es importante porque facilita el uso de la función de pérdida categorical_crossentropy, que espera que las clases estén en formato one-hot. Así, la red neuronal no predice un número directamente, sino una probabilidad para cada una de las 10 clases posibles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además, esto permite que la red:\n",
    "\n",
    "- Aprenda de manera más robusta al separar las clases de forma explícita.\n",
    "\n",
    "- Genere una distribución de probabilidades sobre todas las clases.\n",
    "\n",
    "- Sea más flexible en problemas de clasificación multiclase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dI3IAhOQ8zHi"
   },
   "source": [
    "## 3. Creación del Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yYUWWsszMAKt"
   },
   "source": [
    "Ahora vamos a definir el modelo, pero antes vamos a repasar algunos comandos y conceptos muy útiles:\n",
    "* **Sequential**: Eso define una SECUENCIA de capas en la red neuronal\n",
    "* **Dense**: Añade una capa de neuronas\n",
    "* **Flatten**: ¿Recuerdas cómo eran las imágenes cuando las imprimiste para poder verlas? Un cuadrado, Flatten toma ese cuadrado y lo convierte en un vector de una dimensión.\n",
    "\n",
    "Cada capa de neuronas necesita una función de activación. Normalmente se usa la función relu en las capas intermedias y softmax en la ultima capa (en problemas de clasificación de más de dos items)\n",
    "* **Relu** significa que \"Si X>0 devuelve X, si no, devuelve 0\", así que lo que hace es pasar sólo valores 0 o mayores a la siguiente capa de la red.\n",
    "* **Softmax** toma un conjunto de valores, y escoge el más grande."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QgBW1yE2MwPp"
   },
   "source": [
    " **Pregunta 3.1 (0.5 puntos)**. Utilizando Keras, y preparando los datos de X e Y como fuera necesario, define y entrena una red neuronal que sea capaz de clasificar imágenes de MNIST con las siguientes características:\n",
    "\n",
    "* Una capa de entrada del tamaño adecuado.\n",
    "* Una capa oculta de 512 neuronas.\n",
    "* Una capa final con 10 salidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "aTaD2QXIORwu"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pedro\\anaconda3\\envs\\rn_act1\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Crear el modelo\n",
    "model = Sequential()\n",
    "\n",
    "# Capa oculta con 128 neuronas y activación ReLU\n",
    "model.add(Dense(units=128, activation='relu', input_shape=(784,)))\n",
    "\n",
    "# Capa de salida con 10 neuronas (una por cada dígito), activación softmax\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bxr5hTKYOQnK"
   },
   "source": [
    "**Pregunta 3.2 (0.25 puntos)**: ¿crees conveniente utilizar una capa flatten en este caso? Motiva tu respuesta.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VNjQEtUUG4iI"
   },
   "source": [
    "No es necesario utilizar flatten pues ya hemos hecho la transformación de las matrices 28x28 a vectores de 784 elementos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D8vHUgfz0_ac"
   },
   "source": [
    "**Respuesta a la pregunta 3.2**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QFVEWNBV1WnY"
   },
   "source": [
    "**Pregunta 3.3 (0.25 puntos)**: Utiliza la función summary() para mostrar la estructura de tu modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "YQpJ-DW61lOO"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m100,480\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,290\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,770</span> (397.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m101,770\u001b[0m (397.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,770</span> (397.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m101,770\u001b[0m (397.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nco-l8vx1Kzb"
   },
   "source": [
    "## 4: Compilación y entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "myZQUTCn1yD3"
   },
   "source": [
    "**Pregunta 4.1 (0.5 puntos)**: Compila tu modelo. Utiliza ***categorical_crossentropy*** como función de pérdida, ***Adam*** como optimizador, y monitoriza la ***tasa de acierto*** durante el entrenamiento. Explica qué hace cada cosa en la compilación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "I_CPQN9p2a7J"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TJ_vlOrj2dR7"
   },
   "source": [
    "**Respuesta a la pregunta 4.1**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo se compila usando el optimizador Adam, que es eficiente en muchos problemas de clasificación. Se utiliza categorical_crossentropy como función de pérdida ya que se trabaja con etiquetas codificadas en one-hot. Durante el entrenamiento, se mide la precisión (accuracy) y se evalúa el modelo también sobre un conjunto de validación para observar si mejora o sufre sobreajuste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f7KSdoEr2rLn"
   },
   "source": [
    "**Pregunta 4.2 (0.5 puntos)**: Utiliza la función ***fit()*** para entrenar tu modelo. Para ayudarte en tu primer entrenamiento, utiliza estos valores:\n",
    "*   epochs = 5\n",
    "*   batch_size = 32\n",
    "*   validation_split = 0.25\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "yytNVJf33WFU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1500/1500 - 4s - 3ms/step - accuracy: 0.9175 - loss: 0.2880 - val_accuracy: 0.9556 - val_loss: 0.1602\n",
      "Epoch 2/10\n",
      "1500/1500 - 4s - 2ms/step - accuracy: 0.9631 - loss: 0.1260 - val_accuracy: 0.9688 - val_loss: 0.1072\n",
      "Epoch 3/10\n",
      "1500/1500 - 4s - 3ms/step - accuracy: 0.9742 - loss: 0.0865 - val_accuracy: 0.9722 - val_loss: 0.0960\n",
      "Epoch 4/10\n",
      "1500/1500 - 4s - 2ms/step - accuracy: 0.9800 - loss: 0.0651 - val_accuracy: 0.9725 - val_loss: 0.0914\n",
      "Epoch 5/10\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9843 - loss: 0.0509 - val_accuracy: 0.9730 - val_loss: 0.0935\n",
      "Epoch 6/10\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9880 - loss: 0.0395 - val_accuracy: 0.9743 - val_loss: 0.0856\n",
      "Epoch 7/10\n",
      "1500/1500 - 4s - 2ms/step - accuracy: 0.9904 - loss: 0.0312 - val_accuracy: 0.9745 - val_loss: 0.0967\n",
      "Epoch 8/10\n",
      "1500/1500 - 4s - 3ms/step - accuracy: 0.9926 - loss: 0.0240 - val_accuracy: 0.9757 - val_loss: 0.0941\n",
      "Epoch 9/10\n",
      "1500/1500 - 4s - 3ms/step - accuracy: 0.9939 - loss: 0.0203 - val_accuracy: 0.9759 - val_loss: 0.0949\n",
      "Epoch 10/10\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9948 - loss: 0.0173 - val_accuracy: 0.9766 - val_loss: 0.0936\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train_encoded,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2,\n",
    "                    verbose=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con verbose = 2, se muestran las métricas como accuracy o la función de pérdida de forma resumida por epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hiQ8qAzhRQ4L"
   },
   "source": [
    "# 5: Impacto al variar el número de neuronas en las capas ocultas\n",
    "\n",
    "En este ejercicio vamos a experimentar con nuestra red neuronal cambiando el numero de neuronas por 512 y por otros valores. Para ello, utiliza la red neuronal de la pregunta 3, y su capa oculta cambia el número de neuronas:\n",
    "\n",
    "* **216 neuronas en la capa oculta\n",
    "* **1024 neuronas en la capa oculta\n",
    "\n",
    "y entrena la red en ambos casos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "cdP8ZwuaUV93"
   },
   "outputs": [],
   "source": [
    "model_216 = Sequential()\n",
    "model_216.add(Dense(216, activation='relu', input_shape=(784,)))\n",
    "model_216.add(Dense(10, activation='softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_216.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1500/1500 - 5s - 3ms/step - accuracy: 0.9274 - loss: 0.2536 - val_accuracy: 0.9622 - val_loss: 0.1349\n",
      "Epoch 2/10\n",
      "1500/1500 - 4s - 3ms/step - accuracy: 0.9686 - loss: 0.1058 - val_accuracy: 0.9695 - val_loss: 0.1049\n",
      "Epoch 3/10\n",
      "1500/1500 - 4s - 2ms/step - accuracy: 0.9778 - loss: 0.0722 - val_accuracy: 0.9707 - val_loss: 0.0904\n",
      "Epoch 4/10\n",
      "1500/1500 - 4s - 3ms/step - accuracy: 0.9850 - loss: 0.0506 - val_accuracy: 0.9723 - val_loss: 0.0906\n",
      "Epoch 5/10\n",
      "1500/1500 - 4s - 3ms/step - accuracy: 0.9889 - loss: 0.0363 - val_accuracy: 0.9724 - val_loss: 0.0968\n",
      "Epoch 6/10\n",
      "1500/1500 - 5s - 3ms/step - accuracy: 0.9911 - loss: 0.0282 - val_accuracy: 0.9742 - val_loss: 0.0883\n",
      "Epoch 7/10\n",
      "1500/1500 - 5s - 3ms/step - accuracy: 0.9933 - loss: 0.0215 - val_accuracy: 0.9774 - val_loss: 0.0827\n",
      "Epoch 8/10\n",
      "1500/1500 - 4s - 3ms/step - accuracy: 0.9946 - loss: 0.0174 - val_accuracy: 0.9772 - val_loss: 0.0901\n",
      "Epoch 9/10\n",
      "1500/1500 - 6s - 4ms/step - accuracy: 0.9952 - loss: 0.0151 - val_accuracy: 0.9766 - val_loss: 0.0912\n",
      "Epoch 10/10\n",
      "1500/1500 - 4s - 3ms/step - accuracy: 0.9967 - loss: 0.0109 - val_accuracy: 0.9765 - val_loss: 0.0978\n"
     ]
    }
   ],
   "source": [
    "history_216 = model_216.fit(x_train, y_train_encoded,\n",
    "                            epochs=10,\n",
    "                            batch_size=32,\n",
    "                            validation_split=0.2,\n",
    "                            verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "YXBlbbfuUaPa"
   },
   "outputs": [],
   "source": [
    "model_1024 = Sequential()\n",
    "model_1024.add(Dense(1024, activation='relu', input_shape=(784,)))\n",
    "model_1024.add(Dense(10, activation='softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1024.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1500/1500 - 14s - 9ms/step - accuracy: 0.9387 - loss: 0.2038 - val_accuracy: 0.9628 - val_loss: 0.1218\n",
      "Epoch 2/10\n",
      "1500/1500 - 13s - 8ms/step - accuracy: 0.9742 - loss: 0.0799 - val_accuracy: 0.9688 - val_loss: 0.0980\n",
      "Epoch 3/10\n",
      "1500/1500 - 13s - 9ms/step - accuracy: 0.9837 - loss: 0.0523 - val_accuracy: 0.9735 - val_loss: 0.0934\n",
      "Epoch 4/10\n",
      "1500/1500 - 12s - 8ms/step - accuracy: 0.9885 - loss: 0.0364 - val_accuracy: 0.9759 - val_loss: 0.0838\n",
      "Epoch 5/10\n",
      "1500/1500 - 12s - 8ms/step - accuracy: 0.9912 - loss: 0.0261 - val_accuracy: 0.9779 - val_loss: 0.0860\n",
      "Epoch 6/10\n",
      "1500/1500 - 12s - 8ms/step - accuracy: 0.9931 - loss: 0.0207 - val_accuracy: 0.9795 - val_loss: 0.0814\n",
      "Epoch 7/10\n",
      "1500/1500 - 12s - 8ms/step - accuracy: 0.9934 - loss: 0.0189 - val_accuracy: 0.9781 - val_loss: 0.0897\n",
      "Epoch 8/10\n",
      "1500/1500 - 13s - 8ms/step - accuracy: 0.9954 - loss: 0.0143 - val_accuracy: 0.9775 - val_loss: 0.1102\n",
      "Epoch 9/10\n",
      "1500/1500 - 12s - 8ms/step - accuracy: 0.9950 - loss: 0.0138 - val_accuracy: 0.9774 - val_loss: 0.1056\n",
      "Epoch 10/10\n",
      "1500/1500 - 11s - 7ms/step - accuracy: 0.9970 - loss: 0.0091 - val_accuracy: 0.9769 - val_loss: 0.1120\n"
     ]
    }
   ],
   "source": [
    "history_1024 = model_1024.fit(x_train, y_train_encoded,\n",
    "                            epochs=10,\n",
    "                            batch_size=32,\n",
    "                            validation_split=0.2,\n",
    "                            verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wG0h2HL-Uj93"
   },
   "source": [
    "**Pregunta 5.1 (0.5 puntos)**: ¿Cual es el impacto que tiene la red neuronal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ff9PdKi7wgq"
   },
   "source": [
    "Respuesta a la pregunta 5.1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al comparar los dos modelos, se observa que el modelo con 1024 neuronas alcanza una mayor precisión en entrenamiento mientras que en la validación ha resultado al contrario. Sin embargo, también se tarda más en entrenar la de 1024 y tiene un mayor riesgo de sobreajuste, mientras que la de 128 ha tardado menos en entrenarse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f37cIr81ZYJj"
   },
   "source": [
    "# 6: Número de neuronas de la capa de salida\n",
    "Considerad la capa final, la de salida de la red neuronal de la pregunta 3.\n",
    "\n",
    "**Pregunta 6.1 (0.25 puntos)**: ¿Por qué son 10 las neuronas de la última capa?\n",
    "\n",
    "**Pregunta 6.2 (0.25 puntos)**: ¿Qué pasaría si tuvieras una cantidad diferente a 10?\n",
    "\n",
    "Por ejemplo, intenta entrenar la red con 5, para ello utiliza la red neuronal de la pregunta 1 y cambia a 5 el número de neuronas en la última capa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "FhbZkppYZOCS"
   },
   "outputs": [],
   "source": [
    "# Crear un modelo incorrecto con solo 5 neuronas en la capa de salida\n",
    "model_inc = Sequential()\n",
    "model_inc.add(Dense(128, activation='relu', input_shape=(784,)))\n",
    "model_inc.add(Dense(5, activation='softmax')) \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inc.compile(optimizer='adam',\n",
    "                    loss='categorical_crossentropy',\n",
    "                    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Arguments `target` and `output` must have the same rank (ndim). Received: target.shape=(32,), output.shape=(32, 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Intentar entrenar (esto debería dar error o funcionar mal)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m history_inc = model_inc.fit(x_train, y_train,\n\u001b[32m      3\u001b[39m                                 epochs=\u001b[32m10\u001b[39m,\n\u001b[32m      4\u001b[39m                                 batch_size=\u001b[32m32\u001b[39m,\n\u001b[32m      5\u001b[39m                                 validation_split=\u001b[32m0.2\u001b[39m,\n\u001b[32m      6\u001b[39m                                 verbose=\u001b[32m2\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\rn_act1\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\anaconda3\\envs\\rn_act1\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py:653\u001b[39m, in \u001b[36mcategorical_crossentropy\u001b[39m\u001b[34m(target, output, from_logits, axis)\u001b[39m\n\u001b[32m    647\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    648\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mArguments `target` and `output` must be at least rank 1. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    649\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReceived: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    650\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtarget.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, output.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    651\u001b[39m     )\n\u001b[32m    652\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(target.shape) != \u001b[38;5;28mlen\u001b[39m(output.shape):\n\u001b[32m--> \u001b[39m\u001b[32m653\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    654\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mArguments `target` and `output` must have the same rank \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    655\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m(ndim). Received: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    656\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtarget.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, output.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    657\u001b[39m     )\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m e1, e2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(target.shape, output.shape):\n\u001b[32m    659\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m e1 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e2 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e1 != e2:\n",
      "\u001b[31mValueError\u001b[39m: Arguments `target` and `output` must have the same rank (ndim). Received: target.shape=(32,), output.shape=(32, 5)"
     ]
    }
   ],
   "source": [
    "# Intentar entrenar (esto debería dar error o funcionar mal)\n",
    "history_inc = model_inc.fit(x_train, y_train,\n",
    "                                epochs=10,\n",
    "                                batch_size=32,\n",
    "                                validation_split=0.2,\n",
    "                                verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SLsQcq-6aUoD"
   },
   "source": [
    "Tu respuestas a la pregunta 6.1 aquí:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Porque son el número de clases que se pretende predecir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J1f_7ZFeaUu6"
   },
   "source": [
    "Tu respuestas a la pregunta 6.2 aquí:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la prueba, configuramos la capa de salida con solo 5 neuronas cuando el dataset requiere de 10 clases. Al compilar y entrenar el modelo, se produce un error porque la forma de las etiquetas (10 dimensiones por one-hot encoding) no coincide con la salida del modelo (5 neuronas)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HNIBCkshaf2y"
   },
   "source": [
    "# 7: Aumento de epoch y su efecto en la red neuronal\n",
    "En este ejercicio vamos a ver el impacto de aumentar los epoch en el entrenamiento. Usando la red neuronal de la pregunta 3:\n",
    "\n",
    "**Pregunta 7.1 (0.25 puntos)**\n",
    "* Intentad 15 epoch para su entrenamiento, probablemente obtendras un modelo con una pérdida mucho mejor que el que tiene 5.\n",
    "\n",
    "**Pregunta 7.2 (0.25 puntos)**\n",
    "* Intenta ahora con 30 epoch para su entrenamiento.\n",
    "\n",
    "**Pregunta 7.3 (0.25 puntos)**\n",
    "* ¿Qué está pasando en la pregunta anterior? Explica tu respuesta y da el nombre de este efecto si lo conoces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el modelo\n",
    "model2 = Sequential()\n",
    "\n",
    "# Capa oculta con 128 neuronas y activación ReLU\n",
    "model2.add(Dense(units=128, activation='relu', input_shape=(784,)))\n",
    "\n",
    "# Capa de salida con 10 neuronas (una por cada dígito), activación softmax\n",
    "model2.add(Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "Cb5vk_imG4iZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1500/1500 - 4s - 3ms/step - accuracy: 0.9166 - loss: 0.2938 - val_accuracy: 0.9443 - val_loss: 0.1799\n",
      "Epoch 2/15\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9626 - loss: 0.1312 - val_accuracy: 0.9656 - val_loss: 0.1173\n",
      "Epoch 3/15\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9740 - loss: 0.0887 - val_accuracy: 0.9625 - val_loss: 0.1222\n",
      "Epoch 4/15\n",
      "1500/1500 - 4s - 3ms/step - accuracy: 0.9803 - loss: 0.0666 - val_accuracy: 0.9701 - val_loss: 0.0975\n",
      "Epoch 5/15\n",
      "1500/1500 - 4s - 2ms/step - accuracy: 0.9844 - loss: 0.0516 - val_accuracy: 0.9738 - val_loss: 0.0901\n",
      "Epoch 6/15\n",
      "1500/1500 - 4s - 3ms/step - accuracy: 0.9882 - loss: 0.0398 - val_accuracy: 0.9744 - val_loss: 0.0904\n",
      "Epoch 7/15\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9905 - loss: 0.0312 - val_accuracy: 0.9752 - val_loss: 0.0883\n",
      "Epoch 8/15\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9914 - loss: 0.0269 - val_accuracy: 0.9755 - val_loss: 0.0917\n",
      "Epoch 9/15\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9936 - loss: 0.0217 - val_accuracy: 0.9772 - val_loss: 0.0911\n",
      "Epoch 10/15\n",
      "1500/1500 - 4s - 3ms/step - accuracy: 0.9952 - loss: 0.0165 - val_accuracy: 0.9759 - val_loss: 0.0955\n",
      "Epoch 11/15\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9958 - loss: 0.0146 - val_accuracy: 0.9743 - val_loss: 0.1046\n",
      "Epoch 12/15\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9968 - loss: 0.0112 - val_accuracy: 0.9778 - val_loss: 0.0960\n",
      "Epoch 13/15\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9967 - loss: 0.0105 - val_accuracy: 0.9762 - val_loss: 0.1038\n",
      "Epoch 14/15\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9975 - loss: 0.0089 - val_accuracy: 0.9762 - val_loss: 0.1018\n",
      "Epoch 15/15\n",
      "1500/1500 - 4s - 3ms/step - accuracy: 0.9979 - loss: 0.0072 - val_accuracy: 0.9752 - val_loss: 0.1123\n"
     ]
    }
   ],
   "source": [
    "history_15 = model2.fit(x_train, y_train_encoded,\n",
    "                          epochs=15,\n",
    "                          batch_size=32,\n",
    "                          validation_split=0.2,\n",
    "                          verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el modelo\n",
    "model3 = Sequential()\n",
    "\n",
    "# Capa oculta con 128 neuronas y activación ReLU\n",
    "model3.add(Dense(units=128, activation='relu', input_shape=(784,)))\n",
    "\n",
    "# Capa de salida con 10 neuronas (una por cada dígito), activación softmax\n",
    "model3.add(Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1500/1500 - 4s - 3ms/step - accuracy: 0.9190 - loss: 0.2834 - val_accuracy: 0.9526 - val_loss: 0.1660\n",
      "Epoch 2/30\n",
      "1500/1500 - 4s - 2ms/step - accuracy: 0.9623 - loss: 0.1285 - val_accuracy: 0.9636 - val_loss: 0.1249\n",
      "Epoch 3/30\n",
      "1500/1500 - 4s - 3ms/step - accuracy: 0.9731 - loss: 0.0890 - val_accuracy: 0.9677 - val_loss: 0.1047\n",
      "Epoch 4/30\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9811 - loss: 0.0652 - val_accuracy: 0.9722 - val_loss: 0.0970\n",
      "Epoch 5/30\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9843 - loss: 0.0519 - val_accuracy: 0.9743 - val_loss: 0.0877\n",
      "Epoch 6/30\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9878 - loss: 0.0401 - val_accuracy: 0.9743 - val_loss: 0.0940\n",
      "Epoch 7/30\n",
      "1500/1500 - 4s - 3ms/step - accuracy: 0.9909 - loss: 0.0299 - val_accuracy: 0.9722 - val_loss: 0.0982\n",
      "Epoch 8/30\n",
      "1500/1500 - 4s - 2ms/step - accuracy: 0.9928 - loss: 0.0240 - val_accuracy: 0.9742 - val_loss: 0.0946\n",
      "Epoch 9/30\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9937 - loss: 0.0211 - val_accuracy: 0.9772 - val_loss: 0.0882\n",
      "Epoch 10/30\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9955 - loss: 0.0148 - val_accuracy: 0.9736 - val_loss: 0.1074\n",
      "Epoch 11/30\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9959 - loss: 0.0141 - val_accuracy: 0.9728 - val_loss: 0.1099\n",
      "Epoch 12/30\n",
      "1500/1500 - 5s - 3ms/step - accuracy: 0.9965 - loss: 0.0114 - val_accuracy: 0.9765 - val_loss: 0.1036\n",
      "Epoch 13/30\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9973 - loss: 0.0090 - val_accuracy: 0.9733 - val_loss: 0.1207\n",
      "Epoch 14/30\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9977 - loss: 0.0081 - val_accuracy: 0.9758 - val_loss: 0.1130\n",
      "Epoch 15/30\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9974 - loss: 0.0093 - val_accuracy: 0.9759 - val_loss: 0.1138\n",
      "Epoch 16/30\n",
      "1500/1500 - 4s - 3ms/step - accuracy: 0.9985 - loss: 0.0059 - val_accuracy: 0.9778 - val_loss: 0.1036\n",
      "Epoch 17/30\n",
      "1500/1500 - 4s - 2ms/step - accuracy: 0.9981 - loss: 0.0068 - val_accuracy: 0.9743 - val_loss: 0.1238\n",
      "Epoch 18/30\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9981 - loss: 0.0058 - val_accuracy: 0.9762 - val_loss: 0.1251\n",
      "Epoch 19/30\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9987 - loss: 0.0044 - val_accuracy: 0.9770 - val_loss: 0.1264\n",
      "Epoch 20/30\n",
      "1500/1500 - 5s - 3ms/step - accuracy: 0.9984 - loss: 0.0049 - val_accuracy: 0.9769 - val_loss: 0.1191\n",
      "Epoch 21/30\n",
      "1500/1500 - 5s - 3ms/step - accuracy: 0.9980 - loss: 0.0058 - val_accuracy: 0.9765 - val_loss: 0.1229\n",
      "Epoch 22/30\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9991 - loss: 0.0033 - val_accuracy: 0.9793 - val_loss: 0.1126\n",
      "Epoch 23/30\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9984 - loss: 0.0055 - val_accuracy: 0.9791 - val_loss: 0.1200\n",
      "Epoch 24/30\n",
      "1500/1500 - 4s - 2ms/step - accuracy: 0.9989 - loss: 0.0036 - val_accuracy: 0.9768 - val_loss: 0.1372\n",
      "Epoch 25/30\n",
      "1500/1500 - 4s - 3ms/step - accuracy: 0.9984 - loss: 0.0054 - val_accuracy: 0.9739 - val_loss: 0.1464\n",
      "Epoch 26/30\n",
      "1500/1500 - 4s - 2ms/step - accuracy: 0.9988 - loss: 0.0038 - val_accuracy: 0.9773 - val_loss: 0.1412\n",
      "Epoch 27/30\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9995 - loss: 0.0016 - val_accuracy: 0.9780 - val_loss: 0.1371\n",
      "Epoch 28/30\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9979 - loss: 0.0064 - val_accuracy: 0.9775 - val_loss: 0.1521\n",
      "Epoch 29/30\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9989 - loss: 0.0034 - val_accuracy: 0.9783 - val_loss: 0.1342\n",
      "Epoch 30/30\n",
      "1500/1500 - 4s - 3ms/step - accuracy: 0.9985 - loss: 0.0044 - val_accuracy: 0.9775 - val_loss: 0.1426\n"
     ]
    }
   ],
   "source": [
    "history_30 = model3.fit(x_train, y_train_encoded,\n",
    "                          epochs=30,\n",
    "                          batch_size=32,\n",
    "                          validation_split=0.2,\n",
    "                          verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fs0fjzH4bmSR"
   },
   "source": [
    "Tu respuesta a la pregunta 7.3 aquí:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al aumentar el número de épocas de entrenamiento, el modelo tiene más oportunidades de ajustarse a los datos. Con 15 épocas, la precisión mejora con respecto a 10, y con 30 puede seguir mejorando inicialmente. Sin embargo, si el modelo empieza a aprender demasiado los datos de entrenamiento y pierde capacidad de generalización, puede aparecer sobreajuste. En ese caso, la precisión en validación se estabiliza o incluso disminuye, mientras la de entrenamiento sigue subiendo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HlIgNG4Yb_N6"
   },
   "source": [
    "# 8: Early stop\n",
    "En el ejercicio anterior, cuando entrenabas con epoch extras, tenías un problema en el que tu pérdida podía cambiar. Puede que te haya llevado un poco de tiempo esperar a que el entrenamiento lo hiciera,  y puede que hayas pensado \"¿no estaría bien si pudiera parar el entrenamiento cuando alcance un valor deseado?\", es decir, una precisión del 85% podría ser suficiente para ti, y si alcanzas eso después de 3 epoch, ¿por qué sentarte a esperar a que termine muchas más épocas? Como cualquier otro programa existen formas de parar la ejecución\n",
    "\n",
    "A partir del código de ejemplo, hacer una nueva función que tenga en cuenta la perdida (loss) y que pueda parar el código para evitar que ocurra el efeto secundario que vimos en el ejercicio 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "b5UwceFUG4ic"
   },
   "outputs": [],
   "source": [
    "### Ejemplo de código\n",
    "\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "      def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('accuracy')> 0.85):\n",
    "              print(\"\\nAlcanzado el 85% de precisión, se cancela el entrenamiento!!\")\n",
    "              self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Bjd8wGKccrn"
   },
   "source": [
    "**Pregunta 8.1. *(0.75 puntos)***: Consulta la documentación de Keras y aprende cómo podemos utilizar Early stop en nuestro modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "3P3sQQky8qI6"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Definir el callback de EarlyStopping\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',     # métrica a vigilar\n",
    "    patience=3,             # número de épocas sin mejora antes de detener\n",
    "    restore_best_weights=True  # recupera los mejores pesos\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el modelo\n",
    "model = Sequential()\n",
    "\n",
    "# Capa oculta con 128 neuronas y activación ReLU\n",
    "model.add(Dense(units=128, activation='relu', input_shape=(784,)))\n",
    "\n",
    "# Capa de salida con 10 neuronas (una por cada dígito), activación softmax\n",
    "model.add(Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "                    loss='categorical_crossentropy',\n",
    "                    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1500/1500 - 5s - 3ms/step - accuracy: 0.9194 - loss: 0.2836 - val_accuracy: 0.9563 - val_loss: 0.1535\n",
      "Epoch 2/30\n",
      "1500/1500 - 4s - 3ms/step - accuracy: 0.9623 - loss: 0.1251 - val_accuracy: 0.9643 - val_loss: 0.1153\n",
      "Epoch 3/30\n",
      "1500/1500 - 4s - 2ms/step - accuracy: 0.9742 - loss: 0.0859 - val_accuracy: 0.9674 - val_loss: 0.1093\n",
      "Epoch 4/30\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9808 - loss: 0.0629 - val_accuracy: 0.9716 - val_loss: 0.0955\n",
      "Epoch 5/30\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9854 - loss: 0.0493 - val_accuracy: 0.9713 - val_loss: 0.0974\n",
      "Epoch 6/30\n",
      "1500/1500 - 4s - 2ms/step - accuracy: 0.9881 - loss: 0.0381 - val_accuracy: 0.9728 - val_loss: 0.0936\n",
      "Epoch 7/30\n",
      "1500/1500 - 4s - 3ms/step - accuracy: 0.9909 - loss: 0.0304 - val_accuracy: 0.9752 - val_loss: 0.0888\n",
      "Epoch 8/30\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9928 - loss: 0.0243 - val_accuracy: 0.9746 - val_loss: 0.0925\n",
      "Epoch 9/30\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9940 - loss: 0.0201 - val_accuracy: 0.9771 - val_loss: 0.0863\n",
      "Epoch 10/30\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9956 - loss: 0.0154 - val_accuracy: 0.9693 - val_loss: 0.1108\n",
      "Epoch 11/30\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9958 - loss: 0.0137 - val_accuracy: 0.9754 - val_loss: 0.0953\n",
      "Epoch 12/30\n",
      "1500/1500 - 4s - 3ms/step - accuracy: 0.9971 - loss: 0.0109 - val_accuracy: 0.9738 - val_loss: 0.1063\n"
     ]
    }
   ],
   "source": [
    "history_early = model.fit(x_train, y_train_encoded,\n",
    "                          epochs=30,\n",
    "                          batch_size=32,\n",
    "                          validation_split=0.2,\n",
    "                          callbacks=[early_stop],\n",
    "                          verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras permite usar el callback EarlyStopping para detener el entrenamiento automáticamente cuando una métrica (por ejemplo, val_loss o val_accuracy) deja de mejorar. Esto ayuda a evitar el sobreentrenamiento y reduce el tiempo de computación. Se puede configurar qué métrica observar (monitor), cuántas épocas esperar antes de detener (patience) y si se deben restaurar los mejores pesos (restore_best_weights=True).\n",
    "\n",
    "Esto es útil cuando, como en el ejercicio anterior, la precisión ya es suficiente tras pocas épocas, y seguir entrenando no mejora el modelo e incluso lo empeora."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M_yZ9B8gTFqR"
   },
   "source": [
    "## 9. Unidades de activación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MuVNxmXSTFqR"
   },
   "source": [
    "En este ejercicio, vamos a evaluar la importancia de utilizar las unidades de activación adecuadas. Como hemos visto en clase, funciones de activación como sigmoid han dejado de utilizarse en favor de otras unidades como ReLU.\n",
    "\n",
    "**Pregunta 9.1 *(0.75 puntos)***: Utilizando la red realizada en el ejercicio 3, escribir un breve análisis comparando la utilización de unidades sigmoid y ReLU (por ejemplo, se pueden comentar aspectos como velocidad de convergencia, métricas obtenidas...). Explicar por qué pueden darse estas diferencias. Opcionalmente, comparar con otras activaciones disponibles en Keras.\n",
    "\n",
    "*Pista: Usando redes más grandes se hace más sencillo apreciar las diferencias. Es mejor utilizar al menos 3 o 4 capas densas.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_relu = Sequential()\n",
    "model_relu.add(Dense(128, activation='relu', input_shape=(784,)))\n",
    "model_relu.add(Dense(64, activation='relu'))\n",
    "model_relu.add(Dense(32, activation='relu'))\n",
    "model_relu.add(Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_relu.compile(optimizer='adam',\n",
    "                   loss='categorical_crossentropy',\n",
    "                   metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1500/1500 - 5s - 3ms/step - accuracy: 0.9153 - loss: 0.2791 - val_accuracy: 0.9578 - val_loss: 0.1425\n",
      "Epoch 2/15\n",
      "1500/1500 - 4s - 2ms/step - accuracy: 0.9642 - loss: 0.1175 - val_accuracy: 0.9662 - val_loss: 0.1077\n",
      "Epoch 3/15\n",
      "1500/1500 - 4s - 2ms/step - accuracy: 0.9743 - loss: 0.0836 - val_accuracy: 0.9709 - val_loss: 0.1010\n",
      "Epoch 4/15\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9808 - loss: 0.0638 - val_accuracy: 0.9717 - val_loss: 0.0947\n",
      "Epoch 5/15\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9841 - loss: 0.0500 - val_accuracy: 0.9722 - val_loss: 0.0999\n",
      "Epoch 6/15\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9863 - loss: 0.0418 - val_accuracy: 0.9732 - val_loss: 0.1039\n",
      "Epoch 7/15\n",
      "1500/1500 - 4s - 3ms/step - accuracy: 0.9881 - loss: 0.0358 - val_accuracy: 0.9703 - val_loss: 0.1111\n",
      "Epoch 8/15\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9899 - loss: 0.0300 - val_accuracy: 0.9729 - val_loss: 0.1058\n",
      "Epoch 9/15\n",
      "1500/1500 - 4s - 2ms/step - accuracy: 0.9911 - loss: 0.0271 - val_accuracy: 0.9651 - val_loss: 0.1345\n",
      "Epoch 10/15\n",
      "1500/1500 - 4s - 3ms/step - accuracy: 0.9916 - loss: 0.0243 - val_accuracy: 0.9758 - val_loss: 0.0995\n",
      "Epoch 11/15\n",
      "1500/1500 - 4s - 3ms/step - accuracy: 0.9929 - loss: 0.0220 - val_accuracy: 0.9750 - val_loss: 0.1202\n",
      "Epoch 12/15\n",
      "1500/1500 - 5s - 3ms/step - accuracy: 0.9940 - loss: 0.0177 - val_accuracy: 0.9758 - val_loss: 0.1228\n",
      "Epoch 13/15\n",
      "1500/1500 - 4s - 3ms/step - accuracy: 0.9941 - loss: 0.0183 - val_accuracy: 0.9739 - val_loss: 0.1283\n",
      "Epoch 14/15\n",
      "1500/1500 - 4s - 3ms/step - accuracy: 0.9938 - loss: 0.0185 - val_accuracy: 0.9743 - val_loss: 0.1233\n",
      "Epoch 15/15\n",
      "1500/1500 - 4s - 3ms/step - accuracy: 0.9950 - loss: 0.0151 - val_accuracy: 0.9728 - val_loss: 0.1246\n"
     ]
    }
   ],
   "source": [
    "history_relu = model_relu.fit(x_train, y_train_encoded,\n",
    "                              epochs=15,\n",
    "                              batch_size=32,\n",
    "                              validation_split=0.2,\n",
    "                              verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sigmoid = Sequential()\n",
    "model_sigmoid.add(Dense(128, activation='sigmoid', input_shape=(784,)))\n",
    "model_sigmoid.add(Dense(64, activation='sigmoid'))\n",
    "model_sigmoid.add(Dense(32, activation='sigmoid'))\n",
    "model_sigmoid.add(Dense(10, activation='softmax'))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sigmoid.compile(optimizer='adam',\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1500/1500 - 7s - 4ms/step - accuracy: 0.8336 - loss: 0.7202 - val_accuracy: 0.9316 - val_loss: 0.2570\n",
      "Epoch 2/15\n",
      "1500/1500 - 4s - 3ms/step - accuracy: 0.9404 - loss: 0.2137 - val_accuracy: 0.9506 - val_loss: 0.1746\n",
      "Epoch 3/15\n",
      "1500/1500 - 4s - 2ms/step - accuracy: 0.9583 - loss: 0.1459 - val_accuracy: 0.9602 - val_loss: 0.1402\n",
      "Epoch 4/15\n",
      "1500/1500 - 4s - 3ms/step - accuracy: 0.9685 - loss: 0.1099 - val_accuracy: 0.9657 - val_loss: 0.1222\n",
      "Epoch 5/15\n",
      "1500/1500 - 5s - 3ms/step - accuracy: 0.9758 - loss: 0.0845 - val_accuracy: 0.9677 - val_loss: 0.1078\n",
      "Epoch 6/15\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9806 - loss: 0.0678 - val_accuracy: 0.9688 - val_loss: 0.1078\n",
      "Epoch 7/15\n",
      "1500/1500 - 4s - 3ms/step - accuracy: 0.9847 - loss: 0.0533 - val_accuracy: 0.9697 - val_loss: 0.1024\n",
      "Epoch 8/15\n",
      "1500/1500 - 4s - 3ms/step - accuracy: 0.9875 - loss: 0.0444 - val_accuracy: 0.9678 - val_loss: 0.1051\n",
      "Epoch 9/15\n",
      "1500/1500 - 5s - 3ms/step - accuracy: 0.9897 - loss: 0.0357 - val_accuracy: 0.9710 - val_loss: 0.0988\n",
      "Epoch 10/15\n",
      "1500/1500 - 4s - 2ms/step - accuracy: 0.9917 - loss: 0.0299 - val_accuracy: 0.9745 - val_loss: 0.0928\n",
      "Epoch 11/15\n",
      "1500/1500 - 4s - 2ms/step - accuracy: 0.9936 - loss: 0.0241 - val_accuracy: 0.9715 - val_loss: 0.1014\n",
      "Epoch 12/15\n",
      "1500/1500 - 5s - 3ms/step - accuracy: 0.9947 - loss: 0.0196 - val_accuracy: 0.9729 - val_loss: 0.1039\n",
      "Epoch 13/15\n",
      "1500/1500 - 5s - 3ms/step - accuracy: 0.9954 - loss: 0.0163 - val_accuracy: 0.9707 - val_loss: 0.1114\n",
      "Epoch 14/15\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9964 - loss: 0.0140 - val_accuracy: 0.9734 - val_loss: 0.1101\n",
      "Epoch 15/15\n",
      "1500/1500 - 4s - 2ms/step - accuracy: 0.9969 - loss: 0.0120 - val_accuracy: 0.9721 - val_loss: 0.1166\n"
     ]
    }
   ],
   "source": [
    "history_sigmoid = model_sigmoid.fit(x_train, y_train_encoded,\n",
    "                                    epochs=15,\n",
    "                                    batch_size=32,\n",
    "                                    validation_split=0.2,\n",
    "                                    verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la comparación realizada entre las funciones de activación ReLU y Sigmoid, se observa que ambas alcanzan precisiones similares tras 15 épocas, con valores cercanos al 88%. Sin embargo, ReLU muestra una convergencia más rápida, obteniendo altos valores de precisión en menos épocas.\n",
    "\n",
    "Esto se debe a que ReLU no satura en los extremos y permite flujos de gradiente más estables, mientras que Sigmoid puede sufrir el problema del desvanecimiento del gradiente, especialmente en redes profundas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pu6RbUFKTFqT"
   },
   "source": [
    "## 10. Inicialización de parámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Abmm05UPTFqU"
   },
   "source": [
    "En este ejercicio, vamos a evaluar la importancia de una correcta inicialización de parámetros en una red neuronal.\n",
    "\n",
    "**Pregunta 10.1 *(0.75 puntos)***: Partiendo de una red similar a la del ejercicio anterior (usando ya ReLUs), comentar las diferencias que se aprecian en el entrenamiento al utilizar distintas estrategias de inicialización de parámetros. Para ello, inicializar todas las capas con las siguientes estrategias, disponibles en Keras, y analizar sus diferencias:\n",
    "\n",
    "* Inicialización con ceros.\n",
    "* Inicialización con una variable aleatoria normal.\n",
    "* Inicialización con los valores por defecto de Keras para una capa Dense (estrategia *glorot uniform*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "qcMt7pSkTFqU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1500/1500 - 5s - 3ms/step - accuracy: 0.1139 - loss: 2.3014 - val_accuracy: 0.1060 - val_loss: 2.3020\n",
      "Epoch 2/10\n",
      "1500/1500 - 4s - 3ms/step - accuracy: 0.1140 - loss: 2.3012 - val_accuracy: 0.1060 - val_loss: 2.3021\n",
      "Epoch 3/10\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.1140 - loss: 2.3012 - val_accuracy: 0.1060 - val_loss: 2.3021\n",
      "Epoch 4/10\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.1140 - loss: 2.3011 - val_accuracy: 0.1060 - val_loss: 2.3021\n",
      "Epoch 5/10\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.1140 - loss: 2.3012 - val_accuracy: 0.1060 - val_loss: 2.3023\n",
      "Epoch 6/10\n",
      "1500/1500 - 4s - 2ms/step - accuracy: 0.1140 - loss: 2.3011 - val_accuracy: 0.1060 - val_loss: 2.3020\n",
      "Epoch 7/10\n",
      "1500/1500 - 4s - 2ms/step - accuracy: 0.1140 - loss: 2.3012 - val_accuracy: 0.1060 - val_loss: 2.3019\n",
      "Epoch 8/10\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.1140 - loss: 2.3011 - val_accuracy: 0.1060 - val_loss: 2.3022\n",
      "Epoch 9/10\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.1140 - loss: 2.3012 - val_accuracy: 0.1060 - val_loss: 2.3020\n",
      "Epoch 10/10\n",
      "1500/1500 - 4s - 3ms/step - accuracy: 0.1140 - loss: 2.3011 - val_accuracy: 0.1060 - val_loss: 2.3021\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.initializers import Zeros\n",
    "\n",
    "model_zeros = Sequential()\n",
    "model_zeros.add(Dense(128, activation='relu', input_shape=(784,), kernel_initializer=Zeros()))\n",
    "model_zeros.add(Dense(10, activation='softmax', kernel_initializer=Zeros()))\n",
    "\n",
    "model_zeros.compile(optimizer='adam',\n",
    "                    loss='categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "history_zeros = model_zeros.fit(x_train, y_train_encoded,\n",
    "                                epochs=10,\n",
    "                                batch_size=32,\n",
    "                                validation_split=0.2,\n",
    "                                verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1500/1500 - 6s - 4ms/step - accuracy: 0.9098 - loss: 0.3192 - val_accuracy: 0.9513 - val_loss: 0.1708\n",
      "Epoch 2/10\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9588 - loss: 0.1396 - val_accuracy: 0.9659 - val_loss: 0.1181\n",
      "Epoch 3/10\n",
      "1500/1500 - 5s - 3ms/step - accuracy: 0.9722 - loss: 0.0940 - val_accuracy: 0.9700 - val_loss: 0.1026\n",
      "Epoch 4/10\n",
      "1500/1500 - 4s - 3ms/step - accuracy: 0.9789 - loss: 0.0696 - val_accuracy: 0.9730 - val_loss: 0.0858\n",
      "Epoch 5/10\n",
      "1500/1500 - 4s - 3ms/step - accuracy: 0.9835 - loss: 0.0547 - val_accuracy: 0.9711 - val_loss: 0.0983\n",
      "Epoch 6/10\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9877 - loss: 0.0420 - val_accuracy: 0.9722 - val_loss: 0.0947\n",
      "Epoch 7/10\n",
      "1500/1500 - 4s - 2ms/step - accuracy: 0.9899 - loss: 0.0338 - val_accuracy: 0.9768 - val_loss: 0.0804\n",
      "Epoch 8/10\n",
      "1500/1500 - 4s - 3ms/step - accuracy: 0.9924 - loss: 0.0265 - val_accuracy: 0.9746 - val_loss: 0.0941\n",
      "Epoch 9/10\n",
      "1500/1500 - 4s - 3ms/step - accuracy: 0.9942 - loss: 0.0205 - val_accuracy: 0.9768 - val_loss: 0.0923\n",
      "Epoch 10/10\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9947 - loss: 0.0185 - val_accuracy: 0.9762 - val_loss: 0.0880\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.initializers import RandomNormal\n",
    "\n",
    "model_normal = Sequential()\n",
    "model_normal.add(Dense(128, activation='relu', input_shape=(784,), kernel_initializer=RandomNormal()))\n",
    "model_normal.add(Dense(10, activation='softmax', kernel_initializer=RandomNormal()))\n",
    "\n",
    "model_normal.compile(optimizer='adam',\n",
    "                     loss='categorical_crossentropy',\n",
    "                     metrics=['accuracy'])\n",
    "\n",
    "history_normal = model_normal.fit(x_train, y_train_encoded,\n",
    "                                  epochs=10,\n",
    "                                  batch_size=32,\n",
    "                                  validation_split=0.2,\n",
    "                                  verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1500/1500 - 4s - 3ms/step - accuracy: 0.9130 - loss: 0.3125 - val_accuracy: 0.9557 - val_loss: 0.1574\n",
      "Epoch 2/10\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9613 - loss: 0.1333 - val_accuracy: 0.9672 - val_loss: 0.1131\n",
      "Epoch 3/10\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9728 - loss: 0.0921 - val_accuracy: 0.9711 - val_loss: 0.0996\n",
      "Epoch 4/10\n",
      "1500/1500 - 4s - 2ms/step - accuracy: 0.9798 - loss: 0.0690 - val_accuracy: 0.9714 - val_loss: 0.0962\n",
      "Epoch 5/10\n",
      "1500/1500 - 4s - 3ms/step - accuracy: 0.9839 - loss: 0.0529 - val_accuracy: 0.9728 - val_loss: 0.0880\n",
      "Epoch 6/10\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9877 - loss: 0.0416 - val_accuracy: 0.9737 - val_loss: 0.0892\n",
      "Epoch 7/10\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9896 - loss: 0.0335 - val_accuracy: 0.9747 - val_loss: 0.0837\n",
      "Epoch 8/10\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9921 - loss: 0.0264 - val_accuracy: 0.9755 - val_loss: 0.0879\n",
      "Epoch 9/10\n",
      "1500/1500 - 4s - 3ms/step - accuracy: 0.9938 - loss: 0.0207 - val_accuracy: 0.9772 - val_loss: 0.0848\n",
      "Epoch 10/10\n",
      "1500/1500 - 4s - 2ms/step - accuracy: 0.9952 - loss: 0.0168 - val_accuracy: 0.9738 - val_loss: 0.1025\n"
     ]
    }
   ],
   "source": [
    "model_normal = Sequential()\n",
    "model_normal.add(Dense(128, activation='relu', input_shape=(784,)))\n",
    "model_normal.add(Dense(10, activation='softmax', kernel_initializer=RandomNormal()))\n",
    "\n",
    "model_normal.compile(optimizer='adam',\n",
    "                     loss='categorical_crossentropy',\n",
    "                     metrics=['accuracy'])\n",
    "\n",
    "history_normal = model_normal.fit(x_train, y_train_encoded,\n",
    "                                  epochs=10,\n",
    "                                  batch_size=32,\n",
    "                                  validation_split=0.2,\n",
    "                                  verbose=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La inicialización de pesos es un aspecto fundamental en redes neuronales profundas, ya que condiciona directamente la calidad del entrenamiento y la estabilidad de la propagación del gradiente. En este experimento, hemos comparado tres esquemas de inicialización en una red multicapa con activaciones ReLU:\n",
    "\n",
    "Inicialización con ceros: esta estrategia impide el aprendizaje efectivo, ya que todos los nodos comienzan con pesos idénticos. Como consecuencia, todas las neuronas aprenden las mismas características (falta de ruptura de simetría), y el gradiente que reciben es el mismo. La red no converge.\n",
    "\n",
    "Inicialización aleatoria normal: si bien introduce la ruptura de simetría, puede generar problemas si los valores iniciales están mal escalados, especialmente en redes profundas con ReLU, donde la activación puede \"apagarse\" (output = 0) para muchas neuronas. En nuestro caso, el entrenamiento funciona, pero con oscilaciones mayores.\n",
    "\n",
    "Inicialización glorot_uniform (por defecto en Keras): esta técnica balancea la varianza de los pesos considerando el número de entradas y salidas de cada capa. Permite una propagación estable del gradiente y una convergencia más rápida, especialmente adecuada para activaciones ReLU y redes densas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NqIAyVWrTFqV"
   },
   "source": [
    "## 11. Optimizadores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lcYj29hYTFqW"
   },
   "source": [
    "**Problema 11.1 *(0.75 puntos)***: Partiendo de una red similar a la del ejercicio anterior (utilizando la mejor estrategia de inicialización observada), comparar y analizar las diferencias que se observan  al entrenar con varios de los optimizadores vistos en clase, incluyendo SGD como optimizador básico (se puede explorar el espacio de hiperparámetros de cada optimizador, aunque para optimizadores más avanzados del estilo de RMSprop es buena idea dejar los valores por defecto provistos por Keras)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "model_sgd = Sequential()\n",
    "model_sgd.add(Dense(128, activation='relu', input_shape=(784,)))\n",
    "model_sgd.add(Dense(10, activation='softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sgd.compile(optimizer=SGD(learning_rate=0.01),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1500/1500 - 4s - 2ms/step - accuracy: 0.8305 - loss: 0.6923 - val_accuracy: 0.8983 - val_loss: 0.3744\n",
      "Epoch 2/15\n",
      "1500/1500 - 4s - 2ms/step - accuracy: 0.9001 - loss: 0.3596 - val_accuracy: 0.9149 - val_loss: 0.3084\n",
      "Epoch 3/15\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9126 - loss: 0.3101 - val_accuracy: 0.9212 - val_loss: 0.2772\n",
      "Epoch 4/15\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9217 - loss: 0.2796 - val_accuracy: 0.9283 - val_loss: 0.2544\n",
      "Epoch 5/15\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9277 - loss: 0.2571 - val_accuracy: 0.9327 - val_loss: 0.2364\n",
      "Epoch 6/15\n",
      "1500/1500 - 4s - 3ms/step - accuracy: 0.9330 - loss: 0.2385 - val_accuracy: 0.9358 - val_loss: 0.2222\n",
      "Epoch 7/15\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9371 - loss: 0.2229 - val_accuracy: 0.9410 - val_loss: 0.2109\n",
      "Epoch 8/15\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9405 - loss: 0.2095 - val_accuracy: 0.9439 - val_loss: 0.2004\n",
      "Epoch 9/15\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9443 - loss: 0.1976 - val_accuracy: 0.9476 - val_loss: 0.1900\n",
      "Epoch 10/15\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9471 - loss: 0.1868 - val_accuracy: 0.9486 - val_loss: 0.1834\n",
      "Epoch 11/15\n",
      "1500/1500 - 4s - 3ms/step - accuracy: 0.9503 - loss: 0.1773 - val_accuracy: 0.9512 - val_loss: 0.1757\n",
      "Epoch 12/15\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9523 - loss: 0.1687 - val_accuracy: 0.9535 - val_loss: 0.1688\n",
      "Epoch 13/15\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9548 - loss: 0.1608 - val_accuracy: 0.9538 - val_loss: 0.1634\n",
      "Epoch 14/15\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9570 - loss: 0.1539 - val_accuracy: 0.9553 - val_loss: 0.1581\n",
      "Epoch 15/15\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9590 - loss: 0.1477 - val_accuracy: 0.9567 - val_loss: 0.1533\n"
     ]
    }
   ],
   "source": [
    "history_sgd = model_sgd.fit(x_train, y_train_encoded,\n",
    "                            epochs=15,\n",
    "                            batch_size=32,\n",
    "                            validation_split=0.2,\n",
    "                            verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "model_rmsprop = Sequential()\n",
    "model_rmsprop.add(Dense(128, activation='relu', input_shape=(784,)))\n",
    "model_rmsprop.add(Dense(10, activation='softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rmsprop.compile(optimizer=RMSprop(),  \n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1500/1500 - 6s - 4ms/step - accuracy: 0.9199 - loss: 0.2819 - val_accuracy: 0.9567 - val_loss: 0.1507\n",
      "Epoch 2/15\n",
      "1500/1500 - 4s - 3ms/step - accuracy: 0.9615 - loss: 0.1309 - val_accuracy: 0.9660 - val_loss: 0.1235\n",
      "Epoch 3/15\n",
      "1500/1500 - 4s - 3ms/step - accuracy: 0.9722 - loss: 0.0933 - val_accuracy: 0.9698 - val_loss: 0.1058\n",
      "Epoch 4/15\n",
      "1500/1500 - 4s - 2ms/step - accuracy: 0.9784 - loss: 0.0739 - val_accuracy: 0.9706 - val_loss: 0.1049\n",
      "Epoch 5/15\n",
      "1500/1500 - 4s - 3ms/step - accuracy: 0.9829 - loss: 0.0596 - val_accuracy: 0.9673 - val_loss: 0.1214\n",
      "Epoch 6/15\n",
      "1500/1500 - 4s - 2ms/step - accuracy: 0.9853 - loss: 0.0505 - val_accuracy: 0.9721 - val_loss: 0.1073\n",
      "Epoch 7/15\n",
      "1500/1500 - 4s - 2ms/step - accuracy: 0.9875 - loss: 0.0432 - val_accuracy: 0.9724 - val_loss: 0.1062\n",
      "Epoch 8/15\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9890 - loss: 0.0380 - val_accuracy: 0.9732 - val_loss: 0.1058\n",
      "Epoch 9/15\n",
      "1500/1500 - 4s - 3ms/step - accuracy: 0.9906 - loss: 0.0321 - val_accuracy: 0.9741 - val_loss: 0.1066\n",
      "Epoch 10/15\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9921 - loss: 0.0273 - val_accuracy: 0.9754 - val_loss: 0.1077\n",
      "Epoch 11/15\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9932 - loss: 0.0230 - val_accuracy: 0.9728 - val_loss: 0.1236\n",
      "Epoch 12/15\n",
      "1500/1500 - 4s - 3ms/step - accuracy: 0.9940 - loss: 0.0205 - val_accuracy: 0.9758 - val_loss: 0.1142\n",
      "Epoch 13/15\n",
      "1500/1500 - 4s - 3ms/step - accuracy: 0.9951 - loss: 0.0169 - val_accuracy: 0.9764 - val_loss: 0.1141\n",
      "Epoch 14/15\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9958 - loss: 0.0145 - val_accuracy: 0.9746 - val_loss: 0.1156\n",
      "Epoch 15/15\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9965 - loss: 0.0124 - val_accuracy: 0.9760 - val_loss: 0.1145\n"
     ]
    }
   ],
   "source": [
    "history_rmsprop = model_rmsprop.fit(x_train, y_train_encoded,\n",
    "                                    epochs=15,\n",
    "                                    batch_size=32,\n",
    "                                    validation_split=0.2,\n",
    "                                    verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model_adam = Sequential()\n",
    "model_adam.add(Dense(128, activation='relu', input_shape=(784,)))\n",
    "model_adam.add(Dense(10, activation='softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_adam.compile(optimizer=Adam(),\n",
    "                   loss='categorical_crossentropy',\n",
    "                   metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1500/1500 - 4s - 3ms/step - accuracy: 0.9171 - loss: 0.2883 - val_accuracy: 0.9535 - val_loss: 0.1610\n",
      "Epoch 2/15\n",
      "1500/1500 - 4s - 3ms/step - accuracy: 0.9626 - loss: 0.1294 - val_accuracy: 0.9650 - val_loss: 0.1189\n",
      "Epoch 3/15\n",
      "1500/1500 - 4s - 3ms/step - accuracy: 0.9734 - loss: 0.0896 - val_accuracy: 0.9680 - val_loss: 0.1075\n",
      "Epoch 4/15\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9802 - loss: 0.0668 - val_accuracy: 0.9706 - val_loss: 0.0985\n",
      "Epoch 5/15\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9850 - loss: 0.0506 - val_accuracy: 0.9718 - val_loss: 0.0952\n",
      "Epoch 6/15\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9876 - loss: 0.0398 - val_accuracy: 0.9747 - val_loss: 0.0875\n",
      "Epoch 7/15\n",
      "1500/1500 - 5s - 3ms/step - accuracy: 0.9902 - loss: 0.0313 - val_accuracy: 0.9768 - val_loss: 0.0830\n",
      "Epoch 8/15\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9926 - loss: 0.0249 - val_accuracy: 0.9738 - val_loss: 0.0915\n",
      "Epoch 9/15\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9935 - loss: 0.0214 - val_accuracy: 0.9747 - val_loss: 0.0930\n",
      "Epoch 10/15\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9950 - loss: 0.0166 - val_accuracy: 0.9769 - val_loss: 0.0931\n",
      "Epoch 11/15\n",
      "1500/1500 - 4s - 3ms/step - accuracy: 0.9953 - loss: 0.0148 - val_accuracy: 0.9758 - val_loss: 0.0996\n",
      "Epoch 12/15\n",
      "1500/1500 - 4s - 2ms/step - accuracy: 0.9965 - loss: 0.0120 - val_accuracy: 0.9759 - val_loss: 0.1031\n",
      "Epoch 13/15\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9966 - loss: 0.0106 - val_accuracy: 0.9766 - val_loss: 0.1005\n",
      "Epoch 14/15\n",
      "1500/1500 - 4s - 2ms/step - accuracy: 0.9969 - loss: 0.0100 - val_accuracy: 0.9726 - val_loss: 0.1149\n",
      "Epoch 15/15\n",
      "1500/1500 - 3s - 2ms/step - accuracy: 0.9972 - loss: 0.0087 - val_accuracy: 0.9768 - val_loss: 0.1085\n"
     ]
    }
   ],
   "source": [
    "history_adam = model_adam.fit(x_train, y_train_encoded,\n",
    "                              epochs=15,\n",
    "                              batch_size=32,\n",
    "                              validation_split=0.2,\n",
    "                              verbose=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0fWDiqXvTFqW"
   },
   "source": [
    "Los optimizadores afectan directamente la velocidad y calidad del entrenamiento. SGD, al ser el método más simple, requiere una tasa de aprendizaje bien ajustada y puede converger lentamente o quedarse atrapado en mínimos locales. RMSprop, diseñado para problemas con datos ruidosos o no estacionarios, adapta el tamaño del paso por parámetro, mejorando la estabilidad del aprendizaje. Adam combina ventajas de RMSprop y momentum, y suele ofrecer un excelente rendimiento sin apenas ajuste de hiperparámetros.\n",
    "\n",
    "En nuestras pruebas, Adam mostró la mejor velocidad de convergencia y precisión final, seguido de RMSprop. SGD fue el más lento, y su rendimiento dependió fuertemente de la tasa de aprendizaje usada. Estos resultados confirman que, para tareas generales de clasificación, Adam es una opción robusta por defecto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BkfTFoJOTFqZ"
   },
   "source": [
    "## 12. Regularización y red final *(1.25 puntos)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f6CQhK7ZTFqZ"
   },
   "source": [
    "**Problema 12.1 *(2 puntos)***: Entrenar una red final que sea capaz de obtener una accuracy en el validation superior al 95%. Para ello, combinar todo lo aprendido anteriormente y utilizar técnicas de regularización para evitar overfitting. Algunos de los elementos que pueden tenerse en cuenta son los siguientes.\n",
    "\n",
    "* Número de capas y neuronas por capa\n",
    "* Optimizadores y sus parámetros\n",
    "* Batch size\n",
    "* Unidades de activación\n",
    "* Uso de capas dropout, regularización L2, regularización L1...\n",
    "* Early stopping (se puede aplicar como un callback de Keras, o se puede ver un poco \"a ojo\" cuándo el modelo empieza a caer en overfitting y seleccionar el número de epochs necesarias)\n",
    "* Batch normalization\n",
    "\n",
    "Si los modelos entrenados anteriormente ya se acercaban al valor requerido de accuracy, probar distintas estrategias igualmente y comentar los resultados.\n",
    "\n",
    "Explicar brevemente la estrategia seguida y los modelos probados para obtener el modelo final, que debe verse entrenado en este Notebook. No es necesario guardar el entrenamiento de todos los modelos que se han probado, es suficiente con explicar cómo se ha llegado al modelo final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final = Sequential()\n",
    "\n",
    "# Capa 1: 128 neuronas, activación ReLU\n",
    "model_final.add(Dense(128, activation='relu', input_shape=(784,)))\n",
    "model_final.add(Dropout(0.2))  # Dropout más bajo para mantener capacidad de aprendizaje\n",
    "\n",
    "# Capa 3: 64 neuronas\n",
    "model_final.add(Dense(64, activation='relu'))\n",
    "model_final.add(Dropout(0.1))  # Dropout más suave en capas profundas\n",
    "\n",
    "# Capa de salida: 10 neuronas (una por dígito), activación softmax\n",
    "model_final.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final.compile(optimizer=Adam(),\n",
    "                    loss='categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=5,\n",
    "    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "375/375 - 2s - 6ms/step - accuracy: 0.8573 - loss: 0.4766 - val_accuracy: 0.9463 - val_loss: 0.1888\n",
      "Epoch 2/50\n",
      "375/375 - 1s - 3ms/step - accuracy: 0.9392 - loss: 0.2085 - val_accuracy: 0.9597 - val_loss: 0.1390\n",
      "Epoch 3/50\n",
      "375/375 - 1s - 3ms/step - accuracy: 0.9542 - loss: 0.1528 - val_accuracy: 0.9655 - val_loss: 0.1157\n",
      "Epoch 4/50\n",
      "375/375 - 1s - 3ms/step - accuracy: 0.9624 - loss: 0.1255 - val_accuracy: 0.9707 - val_loss: 0.0981\n",
      "Epoch 5/50\n",
      "375/375 - 1s - 3ms/step - accuracy: 0.9677 - loss: 0.1053 - val_accuracy: 0.9729 - val_loss: 0.0948\n",
      "Epoch 6/50\n",
      "375/375 - 1s - 3ms/step - accuracy: 0.9709 - loss: 0.0936 - val_accuracy: 0.9732 - val_loss: 0.0901\n",
      "Epoch 7/50\n",
      "375/375 - 1s - 3ms/step - accuracy: 0.9742 - loss: 0.0845 - val_accuracy: 0.9753 - val_loss: 0.0853\n",
      "Epoch 8/50\n",
      "375/375 - 1s - 3ms/step - accuracy: 0.9770 - loss: 0.0749 - val_accuracy: 0.9762 - val_loss: 0.0835\n",
      "Epoch 9/50\n",
      "375/375 - 1s - 3ms/step - accuracy: 0.9785 - loss: 0.0683 - val_accuracy: 0.9774 - val_loss: 0.0808\n",
      "Epoch 10/50\n",
      "375/375 - 1s - 3ms/step - accuracy: 0.9800 - loss: 0.0608 - val_accuracy: 0.9778 - val_loss: 0.0780\n",
      "Epoch 11/50\n",
      "375/375 - 1s - 3ms/step - accuracy: 0.9812 - loss: 0.0569 - val_accuracy: 0.9771 - val_loss: 0.0826\n",
      "Epoch 12/50\n",
      "375/375 - 1s - 3ms/step - accuracy: 0.9821 - loss: 0.0543 - val_accuracy: 0.9782 - val_loss: 0.0796\n",
      "Epoch 13/50\n",
      "375/375 - 1s - 3ms/step - accuracy: 0.9838 - loss: 0.0498 - val_accuracy: 0.9777 - val_loss: 0.0845\n",
      "Epoch 14/50\n",
      "375/375 - 1s - 3ms/step - accuracy: 0.9854 - loss: 0.0445 - val_accuracy: 0.9771 - val_loss: 0.0831\n",
      "Epoch 15/50\n",
      "375/375 - 1s - 3ms/step - accuracy: 0.9858 - loss: 0.0438 - val_accuracy: 0.9785 - val_loss: 0.0795\n",
      "Epoch 16/50\n",
      "375/375 - 1s - 3ms/step - accuracy: 0.9856 - loss: 0.0419 - val_accuracy: 0.9778 - val_loss: 0.0820\n",
      "Epoch 17/50\n",
      "375/375 - 1s - 3ms/step - accuracy: 0.9861 - loss: 0.0401 - val_accuracy: 0.9778 - val_loss: 0.0812\n",
      "Epoch 18/50\n",
      "375/375 - 1s - 3ms/step - accuracy: 0.9879 - loss: 0.0360 - val_accuracy: 0.9790 - val_loss: 0.0832\n",
      "Epoch 19/50\n",
      "375/375 - 1s - 3ms/step - accuracy: 0.9872 - loss: 0.0370 - val_accuracy: 0.9781 - val_loss: 0.0791\n",
      "Epoch 20/50\n",
      "375/375 - 1s - 4ms/step - accuracy: 0.9885 - loss: 0.0338 - val_accuracy: 0.9785 - val_loss: 0.0892\n",
      "Epoch 21/50\n",
      "375/375 - 1s - 3ms/step - accuracy: 0.9874 - loss: 0.0357 - val_accuracy: 0.9792 - val_loss: 0.0849\n",
      "Epoch 22/50\n",
      "375/375 - 1s - 3ms/step - accuracy: 0.9885 - loss: 0.0328 - val_accuracy: 0.9789 - val_loss: 0.0843\n",
      "Epoch 23/50\n",
      "375/375 - 1s - 3ms/step - accuracy: 0.9898 - loss: 0.0296 - val_accuracy: 0.9802 - val_loss: 0.0859\n",
      "Epoch 24/50\n",
      "375/375 - 1s - 3ms/step - accuracy: 0.9897 - loss: 0.0322 - val_accuracy: 0.9772 - val_loss: 0.0934\n",
      "Epoch 25/50\n",
      "375/375 - 1s - 3ms/step - accuracy: 0.9901 - loss: 0.0293 - val_accuracy: 0.9803 - val_loss: 0.0888\n",
      "Epoch 26/50\n",
      "375/375 - 1s - 3ms/step - accuracy: 0.9910 - loss: 0.0268 - val_accuracy: 0.9787 - val_loss: 0.0917\n",
      "Epoch 27/50\n",
      "375/375 - 1s - 3ms/step - accuracy: 0.9898 - loss: 0.0291 - val_accuracy: 0.9794 - val_loss: 0.0871\n",
      "Epoch 28/50\n",
      "375/375 - 1s - 3ms/step - accuracy: 0.9906 - loss: 0.0280 - val_accuracy: 0.9791 - val_loss: 0.0867\n",
      "Epoch 29/50\n",
      "375/375 - 1s - 3ms/step - accuracy: 0.9916 - loss: 0.0241 - val_accuracy: 0.9785 - val_loss: 0.0920\n",
      "Epoch 30/50\n",
      "375/375 - 1s - 4ms/step - accuracy: 0.9917 - loss: 0.0255 - val_accuracy: 0.9795 - val_loss: 0.0857\n"
     ]
    }
   ],
   "source": [
    "history_final = model_final.fit(x_train, y_train_encoded,\n",
    "                                epochs=50,\n",
    "                                batch_size=128,\n",
    "                                validation_split=0.2,\n",
    "                                callbacks=[early_stop],\n",
    "                                verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este ejercicio final, el objetivo era diseñar una red neuronal capaz de superar el 95% de precisión sobre el conjunto de validación. Con base en la experiencia adquirida en los ejercicios anteriores, se planteó una arquitectura sencilla pero efectiva, incorporando buenas prácticas de inicialización, regularización y ajuste de hiperparámetros.\n",
    "\n",
    "*Estrategia seguida*\n",
    "\n",
    "-- Capas y arquitectura:\n",
    "\n",
    "- Capa oculta 1: 128 neuronas con activación ReLU e inicialización de pesos por defecto.\n",
    "\n",
    "- Capa oculta 2: 64 neuronas con activación ReLU.\n",
    "\n",
    "- Capa de salida: 10 neuronas con activación Softmax para clasificación multiclase.\n",
    "\n",
    " -- Regularización:\n",
    "\n",
    "Se aplicó Dropout(0.2) tras la primera capa y Dropout(0.1) tras la segunda, con el objetivo de evitar el sobreajuste sin comprometer la capacidad de aprendizaje.\n",
    "\n",
    "-- Optimizador y función de pérdida:\n",
    "\n",
    "Se utilizó el optimizador Adam, eficaz para problemas de clasificación, junto con la función de pérdida categorical_crossentropy.\n",
    "\n",
    "-- Otros ajustes:\n",
    "\n",
    "- Tamaño del batch: 128\n",
    "\n",
    "- Número de épocas: hasta 50\n",
    "\n",
    "- Validación: 20% de los datos de entrenamiento\n",
    "\n",
    "- EarlyStopping con paciencia de 5 épocas y restauración de los mejores pesos\n",
    "\n",
    "*Resultados*\n",
    "\n",
    "El modelo alcanzó una precisión de validación del 98.02% en la época 25, cumpliendo ampliamente el objetivo. A partir de la época 10 se observaron mejoras más graduales, y gracias al uso de EarlyStopping se evitó el sobreajuste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión final en test: 0.9798\n"
     ]
    }
   ],
   "source": [
    "# Evaluación del modelo en el conjunto de test\n",
    "test_loss, test_accuracy = model_final.evaluate(x_test, y_test_encoded, verbose=0)\n",
    "print(f\"Precisión final en test: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAAHqCAYAAAAZLi26AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAjxpJREFUeJzt3QeYU1X6x/Hf9EIbeu8gvQmC2AtFsfculsW1sHZdO2Jdd/+62Nsu6toL9oIiiooiKIqKSK/S21BmGKbl/7wnk5lMg2GYzM0k38/zhJt7c3NzcnMm5L3vKTE+n88nAAAAAABQ5WKr/pAAAAAAAMAQdAMAAAAAECIE3QAAAAAAhAhBNwAAAAAAIULQDQAAAABAiBB0AwAAAAAQIgTdAAAAAACECEE3AAAAAAAhQtANAAAAAECIEHQDABBhFi9erDvvvFPz5s1TpPv666911113acuWLV4XBQCAMhF0AwDgkQsuuEDt2rXbo+dMmTJFMTExblmWnTt36rTTTtOCBQu0zz77KJItW7ZMJ554ourUqaN69ep5XRwAAMpE0A0AiBrPP/+8C1gDt+TkZBeYjh49WmvXrlUkuPrqq10A+txzz7n3GKlycnJ0xhlnuAsX11xzjdfFAQCgXPHlPwQAQGSy5sjt27dXVlaWpk6dqieffFIff/yxZs+erdTU1Gorx7PPPqv8/Pw9es4hhxyiHTt2KDExsdRjGzZsUPPmzfWPf/yjzMcjye+//64zzzxTV111lddFAQBgl2J8Pp9v17sAABA5me4LL7xQP/zwgwYMGFC4/brrrtNDDz2kV155RWeddVaZz83IyFCtWrWqsbTRyS6E2AWD2Fga4wEAIgP/owEAot4RRxzhlkuWLHFLa7Jcu3ZtLVq0SCNGjHB9hs855xz3mGWmx40bpx49erjm6U2bNtVf//pXbd68udRxP/nkEx166KHu+XXr1tV+++3nAvtd9el+7bXX1L9//8Ln9OrVSw8//PBu+3S/+eab7nkpKSlq1KiRzj33XK1cubLYPoH3ZdutL7Tdb9y4sa6//nrl5eXt9jxZWY899lh99tln6tu3r3v/3bt319tvv13mYG7Wt7xBgwau9cD++++vjz76qNg+gfdi7/m2225Ty5Yt3b5bt24ttwwVPf9VXdbABQEboM66JNjxrFXBySef7OpJwP/93//pgAMOUMOGDd1nYZ/JW2+9tdtzCwCIXATdAICoFwiaLFAKyM3N1fDhw9WkSRMXSJ1yyiluuwV4N9xwgw488EAXDFvm/OWXX3b7Wj/j4Kz6Mccco02bNunmm292Tb4t+Js4cWK55Zg0aZLLtNevX18PPPCAe85hhx2mb7/9dpflt9c6/fTTFRcXp/vvv1+jRo1yweVBBx2k9PT0YvtacG1ltfdq78suCjz44IN65plnKnSubIA260t99NFHu9eKj493AauVPcD6x1vg+emnn+ryyy/Xvffe6wLW448/Xu+8806pY959990uyLXg/7777ttl0/iKnv+qLqudNwvix44d6wJpO2fWtN1GTbduCQFWpn79+rkuDPZeAq9ZVhAPAIgS1rwcAIBo8Nxzz1mXKt/nn3/uW79+vW/FihW+1157zdewYUNfSkqK788//3T7jRw50u130003FXv+N99847a//PLLxbZPnDix2Pb09HRfnTp1fIMGDfLt2LGj2L75+fmF9+112rZtW7h+1VVX+erWrevLzc0t9z18+eWX7rVsabKzs31NmjTx9ezZs9hrffjhh26/O+64o9jr2ba77rqr2DH79evn69+//27Pn5XVnj9hwoTCbVu2bPE1b97cHSPg6quvdvvZ+QrYtm2br3379r527dr58vLyir2XDh06+DIzM3f7+hU9/6Eo6/jx491+Dz30UKlyBX+mJd+HfT722RxxxBG7fX8AgMhEphsAEHWGDBnimlW3bt3aDcZlzawtq2nNm4NddtllpZpw28jgQ4cOdYOWBW6W+bRjfPnll24/y6Ru27ZNN910k2uGHGxXI4qnpaW5vuPBmdjd+fHHH7Vu3TqXpQ1+Lcuyd+3atcwM66WXXlps/eCDD3ZNrCuiRYsWOumkkwrXrQn8+eefr59//llr1qxx22xQuoEDB7pMe4Cdn0suuURLly7VnDlzih1z5MiRrin27lT0/IeirBMmTHDN9v/2t7+VKlfwZxr8PqzJu2XC7fz+9NNPu31/AIDIxOjlAICo8/jjj7t+udb01/oEd+nSpdTAXfZYq1atSjVXtiDKmpyXxYLf4ObqPXv23KNyWeD8xhtvuObQdgFg2LBhrtn4UUcdtcu5qo29h5Is6LbR2YNZYG4XHIJZc/ay+qSXpVOnTqUuHATmA7cgtVmzZq5MgwYNKvXcbt26FZY5+NzYSPIVUdHzH4qy2mdq59jqxa58+OGHuueeezRr1iw3Z3pAJE/fBgDYNYJuAEDUscxm8OjlZUlKSioViNsgXhbwWR/ispQMZveUHduCNetfbIOw2c3m27bs7AsvvKCqYP2+w01FstzVcf731jfffOP6gtu0bk888YQbaC0hIcF9hsED6AEAogtBNwAAFdSxY0d9/vnnbhCvXQWKtp+xAbYs27onbBCx4447zt0syLTs99NPP63bb7+9zGO1bdvWLefNm1c4CnuAbQs8XlUWLlxo48EUy9zOnz/fLQMjsdtr2muXNHfu3GJlDtX5D0VZ7bWnT5/uBmuzQLos1gTdWhLYRRO7aBNgQTcAIHrRpxsAgAqypt42irWNtl2SjXYeGCncmoXblF82YraNhB3MgsDybNy4sdi6Zdp79+7t7gc3VQ5mGXvL/j711FPF9rEs+R9//OH6dlelVatWFRvV26b3+t///udGZrfm2samWZsxY4amTZtWuJ/1VbcR0i3Ytam7Qnn+Q1FWG73e+o8/9thjpV478JlaKwIL8IOnX7Nm7O+++26l3i8AIDKQ6QYAoIJsei2bssqCaWsGbsG1ZT2tr7EN8mXTRZ166qluwK5///vf+stf/uLm5j777LNdv+lffvlFmZmZ5TYVt/1tijHLWFt/cutP/Oijj7ogMdDHuCR7fZtezKbOsvLZlGM2DZaVxYLGa665pkrPgfWJvvjii/XDDz+4/vDjx493rxeczbUB5F599VXXN/3KK69081/be7Z50C0bXLLZflWf/1CU1Zr4W8B+7bXXuiDdBkez4Nwy79Ya4YQTTnAXOB566CHXB98+c+tjbuMHWAuFX3/9da/OOwCgBvN6+HQAAKp7yrAffvhhl/vZ1Fq1atUq9/FnnnnGTbFl04zZ1GC9evXy3Xjjjb5Vq1YV2+/999/3HXDAAW4/mwps4MCBvldffbXcKcPeeust37Bhw9wUYImJib42bdr4/vrXv/pWr15d7pRhAa+//rqbCispKcnXoEED3znnnFM4Bdru3teYMWPcMXfHynrMMcf4Pv30U1/v3r3da3Xt2tX35ptvltp30aJFvlNPPdWXlpbmS05Odu/dpjELFngvZT1/Vypy/qu6rIHpwG699VY3nVhCQoKvWbNm7nn2/ID//ve/vs6dOxe+ntW5ip5fAEBkirF/vA78AQBA+LPMuY3kbSN0h7uaVFYAQGSjTzcAAAAAACFC0A0AAAAAQIgQdAMAAAAAECL06QYAAAAAIETIdAMAAAAAECIE3QAAAAAAhEh8qA5ck+Xn52vVqlWqU6eOYmJivC4OAAAAACDMWE/tbdu2qUWLFoqNLT+fTdBdBgu4W7du7XUxAAAAAABhbsWKFWrVqlW5jxN0l8Ey3IGTV7duXYWrnJwcffbZZxo2bJgSEhK8Lg5qCOoNKou6g8qg3qCyqDuoLOoOqqvebN261SVrA/FjeQi6yxBoUm4Bd7gH3ampqa6MfKGgoqg3qCzqDiqDeoPKou6gsqg7qO56s7suyQykBgAAAABAiBB0AwAAAAAQIgTdAAAAAACECH2690JeXp5r++8Ve+34+HhlZWW5sgAVEc31xvrnxMXFeV0MAAAARBGC7krOx7ZmzRqlp6d7Xo5mzZq5UdaZTxwVFe31Ji0tzb3/aHzvAAAAqH4E3ZUQCLibNGniRrjz6sd7fn6+tm/frtq1a+9yMnYgWLTWG7vYkJmZqXXr1rn15s2be10kAAAARAGC7j1kzXEDAXfDhg09D56ys7OVnJwcVcET9k4015uUlBS3tMDb/oZpag4AAIBQi65f3FUg0IfbMtwAap7A366X4zEAAAAgehB0VxL9Qavfjz/+qH//+98uUwtvfP755/rPf/6jmoy/XQAAAFQngm5US5Dz7rvv7tW+69ev12mnnaaePXtGdJPo4Pe/dOlStz5r1qxy958yZYrbp6oG9dvVa86fP18XXHCBBg4cWCWvBQAAAEQD+nR7KC/fpxlLNmndtiw1qZOsge0bKC42dFk4C5heeOGFwqmT2rRpo/PPP1+33HKLm0IqVFavXq369etXel/LbJ933nkaM2aMhg4dqmjRunVrdz4aNWrk+Wvu2LFDZ599tp577jn17t272soDAAAA1HQE3R6ZOHu1xn4wR6u3ZBVua14vWWOO666jeoZuVOWjjjrKBU47d+7Uxx9/rCuuuMIF4DfffHOpfW2wrcTExL1+TZueaW/2tcz2xIkTFW1skK89OXehfE0bgMya9wMAAADYM5HbTjfMA+7LXvqpWMBt1mzJctvt8VBJSkpyQVXbtm112WWXaciQIXr//fcLM+Ennnii7r33XrVo0UJdunRx220+59NPP93Nb9ygQQOdcMIJrhlysPHjx6tHjx7u+DYV0+jRo8tsMm2BvD1m+9jo2VaO+++/v8x9zW+//aYjjjjCBX02Wvwll1ziprsKCJT5//7v/9wxbR+7kLC7QbLee+897bvvvq4MHTp00NixY5Wbm1usHNZ3+aSTTnIDb3Xu3LnwPJXFWgsMGjSo1PY+ffrorrvucvd/+OEHl6m3LHK9evV06KGH6qefftqjpt52oWSfffZx5+Pwww8v9Tls3LhRZ511llq2bOnK3atXL7366qulWg48/PDD7jj2eVmLB/vMy3vNr776yjUpD3y2N910U7Fzddhhh+nKK6/UjTfe6OqH1a8777yz3PcFAAAARBOC7qqa/zc7t0K3bVk5GvP+7/KVdZyC5Z3vz3H77e5Y9rp7y4I3C4QDJk+erHnz5mnSpEn68MMPXfA6fPhw1alTR998842+/fZbN7+zZcwDz3vyySddoGsBsQXJFpx26tSpzNd75JFH3ONvvPGGe52XX35Z7dq1K3PfjIwM99rW3NwC1jfffNMN5BUc0Jsvv/xSixYtcktrPv/888+7W3nsfViz+quuukpz5szR008/7fYPBJ4BFojbxYZff/1VI0aM0DnnnKNNmzaVeUx7bMaMGa4cAb///rt7rjXLNtu2bdPIkSM1depUff/99y6Qt+Pa9oqwix8nn3yyjjvuOBcU/+Uvf3EBcLCsrCz1799fH330kWbPnu0+E2uab2ULvkAwbtw43Xrrre79v/LKK2ratGmZr7ly5UpXxv3220+//PKL+6z/+9//6p577im2n533WrVqafr06frnP//pLjRYHQIAAACiHc3Lq8COnDx1v+PTKjmWhdFrtmap152f7Xbf2XdWvn+zBewWYH/66af629/+VrjdAifL8Aaalb/00ksuM2rbAqM+W/N0y3rbIF7Dhg1zAdh1113ngtgAC9LKsnz5chdsHnTQQe54lukujwWDFkT+73//c+Uyjz32mAs6H3jggcJA0YJy225No7t27apjjjnGvbdRo0aVeVwLpi1YtQDYWKb77rvvdpla6zcenEW3rLG577773AUDC17tgkNJluW3rLaV+fbbb3fb7IKCZb8DFyAsYx/smWeecefRMsnHHnusdscC3o4dO+rBBx9069YSwS5y2LkIsAz39ddfX7hun619xnaRw7LVFuDb+7DA2N6/Nd23Y9rnUZYnnnjC9fO282ufl53fVatW6e9//7vuuOOOwkHtrJ934NzZ52v722cQTX3wAQAAajxL6u3YLG1fK21bI21f579vt8Ta0uFBXVIn3iJt/VPKz5N8+f5lfq7ky5NqNZFOebZo37f/Kq3/w5pc+h93zylYptSXLvmyaN9XzpSWT5N6nCgd97AiAUF3lLHstWWqLYNtwbRlYYObAltz5OB+3JbdXLhwoct0B7Ng2LK669atc0HYkUceWaHXt0DWAjELGC14tWDTAvey/PHHHy6QDQTc5sADD3Tltix5IOi2gNcC7gBrAm3BaHnsPVnGPjiznZeX595TZmZm4TzOwQOGWRnq1q3r3m95LNttzewt6LaLGtas+9prry18fO3atbrtttvcxQo7jr2mvZ5diKgIOx8lm7APHjy42Lod0y4QWJBtWWprjWD99wPvyY5h69a0vaKvaa8RPM2WfQbWxP/PP/90TdNNycHV7DPY1bkCAABANcrdWTyADgTUSbWlA4oScBrXS9qyouxjNOpSPOhe+Lm0YV7Z+9ZrXXx9wzxp9S9l77tza4n1bVJWurSzqEtpTUfQXQVSEuI0567hFdrXRiu/4Lkfdrvf8xfu50Yz35WkuBhtK94tfLesH7BlTC2wtn7bJUctDw5wjQVX1lzZsrYlNW7ceI+n77J+1EuWLNEnn3zimopb823rV/7WW2+psmwguGAWIO5qLm97T5bttqbaJVkf78oe17LilgG2fto22rc1Bz/jjDMKH7fMsvW5tv7UluG3PtIW0AY3799b//rXv9zxrfm4XUCxz/Pqq68ufA3rThAKe3quAAAAKmXt79K21VLGBiljfcGy4H5KmnTyM4W7xk66TcpcL9VtIdVpIdVtLtVtKdVpLtVpJsUV//1Sc7PSFkwHZaXjk6WBQS0+Hx8krZ9b9jEadi4edNs5tKDbss+1m0m1m0i1m0p1mkr12xd/7iHXS1lbpJhYKTZOiokrWlowH+yof/iD6bL2Lfk5nPiE/yJBcl1FCoLuKmABRmpixU7lwZ0bu1HKbdC0snpkWz6xWb1kt9/upg+rTFBjQVh5/a3LC5Jff/11NWnSxGV6y2J9sq0psQX0FWHHsWDUbqeeeqrLeFtfaRuEK1i3bt1cX2vr2x24GGAZagv0A4O8VYa9J8uU78l5qIhWrVq5DLJdoLCg2zL6dt4CrOzWXNv6SBsLyjds2FDh49v5KDmYm/UND2avYQPdnXvuuYV1xObX7t69e2HTbwu8rUm7BeUVec0JEya4zH0g222vYS0f7P0CAADsteXfS1tXBQXSgdsGKbWhdNYrRfu+MVLauKDs41hgHSR20efSxoVl72vNn28IOs73T0k5GUVBuS0tSE8snpAKqS0rpcyN/iyvBdPuVnDfAtCDryva9z9DpdWzpLwykjcNOxUPuuMSi5YWQBfemkj1S4ytdN57/oA5Pmn35e19esXfW5v9K75v/fK7n9ZUBN3VzAJpmxbMRim3ECY48A6E2PZ4KOfr3hPWZNqypxbI2eBYFmgtW7ZMb7/9tusDbevWPP3SSy91AebRRx/t+g1bYBbcVzzgoYceck2P+/Xr54JnGxzNRru2vs1lvbb1E7YMsb3G+vXr3TFtYLDyBv6qCOuLbM3arWm0Bf1WDmtybgOPlRwgbE8FymyZ5X//+9/FHrOA98UXX9SAAQO0detW3XDDDXuUebZzbP257Xk2iNrMmTNLDRhnr2GtBr777jvX193OtzVrDwTdlskP9F23ix8HH3ywO6826NvFF19c6jUvv/xylzW3824D2NnFCnuuNZvf01YOAACghsvLlXJ3SDl2y5RysgqWO6TYeKlNUDe4Wa/4mzDnZvmzocGBdK1G0sgPivZ9b/QuAukSU+k27uIPCO0YtRoX3AruW2Y2uLiH36H4rSv8mfGtK6WttlwlbVvlz9wG++E/ZZchuZ7UtJd04UdF2+ZNtKxbUQY9tYF/3fon27kIzvL+/q4/A22Bc8lg2p5/2nNF+44/StpSTrfDBh2LB932OQQC7uQ0f+beZaWblQ6kz3zFf/HAstdBXQbLVKvhrh9HpRB0e8Dm4X7y3H1LzdPdrBrm6d5T1hf466+/ds2mrTm2BdQ2WJf14Q5kvi0otv7QFmTaIF42JZYFs2WxDKkN4rVgwQLXD9sGXLNpsMoK4Oy1bRAwG6DN9rP1U045xQWSe8NGRLe+7XYRwQYhs6bRNkCYBbJ7y963Baf23mwqs2A26reNJm6ZdhuczPpeBw96tjt2kcCyztdcc40effRRNzCaHeOiiy4q3Mf6jC9evNi9Rztf9npWji1bthTbx6b8sgsZ1h/fLoJYQF8W+6zt87FA3/rXW2sEC87tGAAAoIJNgC3QTF8uxSdKzQpammVukv47VMrO8AesJW/tDpSOLhosVS+f7h+kqnCfuKL7TbpJBxeNI6Mv7vEHu8WOWbB/Whup5ynFB8PK3FAUPAcCaXt+gw7SmUFdDB/pu+v+vqOLZkvRtw+X36S5RHCslv39AWOZgXSJ4Di4PLvh6zLC+sCVfsBai2aXmD2m9xnSpsX+4NwF6auk7O3+CwYl+xx/dmvxDHpckpSQLGVtlVruK436Imjf23cRSHcovm7nIM+aVaf5A+TCW5o/QA92ynj/a9r52V1WOq1E/2pUuxhfVcw7FWEsC2nzKFugUrJJtQWX1ie5ffv2xfr/VkZevs/18V63LUtN6iS7Ptx7kuG2psNWVisjWUdUVLTXm6r8G442NgCjXYSxLhIl+/ED5aHeIKrqjvVDnfGMP8DevExKt9tyfxBrup8gnf6/osDv3mb+IKss+xwtnf1a0frdjctuSmzaHyqNDOqC9o+2/qxqWVoNlP4SNK3ng938md+yNOkuXT6taP2x/aQN8/33E1L9fYdtmZAiNWgvnfNm0b6fj/VneO2xpDrFg2kLLpv2UNjXHQuiLQC3z7V50KCxb17oD7otMLcLFiUD6St/Llr/4Cp/ZtuC52LBdJq/iXvb4oPiwjuVqTe7ihuDken2kAXYgzvShAMAACCs2QBQwUG0u7/cv96ir3TC4/79YhOkyXeVERzH+JtJW1PlALvwfcFH/ux3YKql4FtKiQF1T3zSvz0vJ2i/gueVzILuf5k/g17quHml97UMuWW1LTiOT/EvXSCd7A8Sg/3lc3+/YAu2d9dMeUjRNKw1lvWjLmswr+Am4RaQu8A8uyCwDvqMTYRMeYW9Q9ANAACAXffjtaDCMnqpjQqasxZNL1rjWcZ5x6aCJsWr/YF0Ul2pzxlFj/+zQ/lZ5uCRly2QHnCxP2BNa+tvym39a+u1KrsJcOv9Kl7OXmV33SvTYTdVfN/gAbd2p2RACf/nWrIPNVACQTcAAEA0s7lwt/zpv1lg2dU/y4bznyHSyp8kX17x51gW1ga0umhi0ba5H0v5Of6MrptiqFnFRkAOFetBaU2sbTAvC6htaqIOhxY9/sJx0qYl/set3MFa7FsUdFsgbUGzDXzlgui2xQPqktMoHf2PanhzAGoSgm4AAIC98cvr/gGYElP9GVLXJLWelFTPv2y8j/eBpzV7DfjyfmnNb/7BnSzQtv6mARZIBgfdNqeuBdzWbNqmbrLpjCxAtcywDQQW7Mt7pbWzi28LzPVr5yDQl9ks/dY/sFcgOLcmzXvynqy5twXLdpGgWc+ix965tCCQXl3weFB/6Rb9pEumFK2nryg+KJj1N7ayWEBdsr/xZdP82WsAqASCbgAAgF2xEZ1t8Kh1c6V1c/yDYo34V9Hj0x6T1vxa9nMt8L45aOTiNy+QVv1cEJQXBOeB+zawUnCz4LW/+/vaBoJ3C+bLyxwvn+4f2MmCSLsFAkqb99cC22t+K9p30RfSn0GjTBs7fr3W/sGwLKgN9Ne1fsTWv9eOYRlfe8yC9MDgUsFs1GablshllgsC3sD0SMUmSZX08Q3Sut+Lv74F5xb0NuosHfNg4UOxU+6TtiwryljbMjAwWclA2uZ73rykdFbesu+NSlz8sH7Y1jfZpo6y9xfcTLwkAm4Ae4GgGwAAoKQZz0qLp/inPLIsti+/6DEbSGr4/VJcwc8om37JAk6basmmFrIphmzU451b/MF0MDcI19KyX9P2DQ66P7vNHyAHs6mJLPi2APLCj4vvWzKQDthuzactWx3nXx94idT7dH9W25pNW7Bd1mBRpmHH4usWjNucxHYr6fhHy2navab4+TP22jkZxedxttuGef4Rr4PE/vGu/zMoyS5GJAbNh2yG3OlfWpDt5i1uWn7AbFNyAUA1IOgGAADRxQJQC3zX/SGt/8O/tPWLP/dnc83Sb6S5HxZvJm3TJzXu6p8T2ZpYB4Lug66u+Guf/KyUsb4gKLcAPb3ovo1wHcyac9dt6X88MKewZY/t+ZY9Dg6kWw+UkmoXBNEFwbTNzWtLO0ZgP9P7NIWcBeeBqZHsfJUUmArLBedb/MG3XRywZYmMc/5+lypOuf4gujCYbuZvzl9SjxND9Y4AoNIIugEAQGSygM4EmkpPe0L69TVp/Xwpd0fp/a05tg2SZXqfKbXe3x8w2s0yprubIqkiLHNcMntcnlP+U3TfAmzrxxycSXfZ44Jgevi9qpFccG5zF6dJTbqWuUv+gIsUV1Pm6QaAMhB0o8b48ccf9c033+iqq65SbCATAQCI7KDZ+u5m2227f95hW2/Wq2jgrRUz/P143WMZ/qWNxm39etfPk0b/6O+zazLWSat/KWqmbaNvW/bagj1b1mpU9NrBg4mFA8tUB4JTAECNQtCNkIuJidE777yjE088sdL7rl+/XqeddpqeeeYZAu4aYMqUKTr88MO1efNmpaXxAxGo9NzIFmBaf1e3zC4+Cvay7/wjT9sgX+6W6V9aBjcvRzr6gaJ9v7hHWvJ10T7GRqO25tG2vOBD/wBYZtrj0uKv/E18LdCzx2Pji/YdeldR/995n/gHBXP7xBU8J77oZn2d4/zBcczy76S1v/mD4uAAOnD/pKel2k2KRte2wclse8kBuMzl3xc1WbY+z1PuL/882sBngaC712lSy/7+ANumegpucg0AQIgQdEeRCy64QC+88IK7n5CQoDZt2uj888/XLbfcovj40FWF1atXq379+pXeNz8/X+edd57GjBmjoUOHKtI/o/T0dL377ruqyQ444AD3WdarV6/Kjrl06VK1b99eP//8s/r27VtlxwWqNWtrUyzZCNPutsAfSB91X9E+r57t70tswWh+bvHnJ9SSbl1VtP7NQ9LCSeW/ng30FbhIaa+3Ynr5+9q0UAGWCV7wafn7HnF70f0Fn0k/ji9/305HSrUKgu55H0kzni5/X5sDORB0W7NpC8aD2QjadmHAbtbUOsCy3r3PKHrMBtayfeu28E/71LBT0b62XnIqKAAAQoygO8ocddRReu6557Rz5059/PHHuuKKK1wAfvPNN5faNzs7W4mJiXv9ms2aNdurfS2zPXHixL0uRyTJyclxn1u4snqzJ587EFFsGqXgaZ0m3+0fBdsCXxs0K1h8ijTsnqLg2LLUbkCtEiyItObUwVM5Ne/tH8zLjmGPBfaxkZrtvs2trILj7n+5P+tsj9v+xoJ6e74FsNbUOmDfkVK7g/2PWbY9sF9ewb7Bg1e1PdAfsNs+wfsG1u1CQQFf835Sr9ODguOCmwuma0u1Gxcd10bX7nuW//mBfcpr5dT1GP8NAIBw5UMpW7ZssbZsblnSjh07fHPmzHFLr+Xl5fk2b97slhUxcuRI3wknnFBs29ChQ337779/scfvueceX/PmzX3t2rVz25cvX+477bTTfPXq1fPVr1/fd/zxx/uWLFlS7Dj//e9/fd27d/clJib6mjVr5rviiisKH7Nz+c4777j7O3fudI/ZPklJSb42bdr47rvvvjL3Nb/++qvv8MMP9yUnJ/saNGjgGzVqlG/btm2l3tO//vUvd0zb5/LLL/dlZ2fv8ly8++67vn79+rkytG/f3nfnnXf6cnJyipXj2Wef9Z144om+lJQUX6dOnXzvvffeLo+ZlZXlu+6663wtWrTwpaam+gYOHOj78ssvCx9/7rnn3DmcOHGir2vXrr5atWr5hg8f7lu1apV7fMyYMe51g2/2fDvXdv+1117zHXLIIa7MdixjZbRj2bYuXbr4Hn/88cLXCzxvwoQJvsMOO8y9j969e/umTp1aWG82bNjgO/PMM12Z7fGePXv6XnnllWLv69BDD/WNHj3ad9VVV/nS0tJ8TZo08T3zzDO+7du3+y644AJf7dq1fR07dvR9/PHHhc+xcttr2+sEfPPNN76DDjrIfZatWrXy/e1vf3PHCGjbtq3v3nvv9V144YXumK1bt/Y9/fTTxT6T4JuVy9j7GDt2rK9ly5au/vXp08f3ySeflPs5hdPfcE1jf1f2t7O7v6+okJvj821Y6PPN+9Tn++5xn++Da3y+54/z+R7s5vPd29Lny88v2vfVs32+MXWLbg929/leON7n+/Ban2/aEz5fTlbRvpuW+o+b/qfPl7HR58veUfxYNRD1BpVF3UFlUXdQXfVmV3FjMDrHViXXT62cm83dWeF9S4yoWtY+VSQlJcVltAMmT56sefPmadKkSfrwww9dRnX48OGqU6eOG8Ts22+/Ve3atV3GPPC8J5980mXML7nkEv322296//331alTUHO+II888oh7/I033nCv8/LLL6tdu3Zl7puRkeFe25qb//DDD3rzzTf1+eefa/To0cX2+/LLL7Vo0SK3tObzzz//vLuVx96HNau3AdnmzJmjp59+2u1/773FR34dO3asTj/9dP36668aMWKEzjnnHG3atKnc41q5pk2bptdee809x/qg23lasGBB4T6ZmZn6v//7P7344ov6+uuvtXz5cl1//fXuMVva69lzrGm23ayZdsBNN93kyvzHH3+482Ln7o477nDltm333Xefbr/99sIuBAG33nqrO/asWbO0zz77uPeRm+tvtpqVlaX+/fvro48+0uzZs91naE35Z8woPterHbNRo0Zu+9/+9jdddtll7v1Z+X766ScNGzbMPc/eX1ns87H3dcopp7hz8/rrr2vq1KmlPssHH3xQAwYMcE3IL7/8cvc6Vk9MoExWB+zcvP3222794Ycfds+z82rHtnNz/PHHFzvvQKXYtR6bvmjJN9JP/ysaCdu8cb706L7SK6dJn94s/fhfaclX0taV/qmdtq8t2nfQX6XTXpAu/Va6ZbV07e/S+e9Jxzwo7X9Z8ay4jZxtI1vXa+mfB9my1lUxYjYAAPBOpS4DRLhKZ7qDMxklby+dWnzfe5qVv+/4EcX3faB96X32MtOdn5/vmzRpksuQXn/99YWPN23a1GWjA1588UWXQbX9A+xxy4p++umnbt2ypLfeemu5rxucvbbs5hFHHFHseOXta9lUy6wHZ0M/+ugjX2xsrG/NmjWFZbYMaW5ubuE+lpU/44wzyi3PkUceWSy7Hniflt0PLsdtt91WuG5lsG3lZVCXLVvmi4uL861cubLUa918883uvmWn7RgLFy4sfNwy03bOd9UaIZCxHjduXLHtll0umZW+++67fYMHDy72vP/85z+Fj//+++9u2/Tp08utN8ccc4zL2AdYRtky1AF2ri1Lf9555xVuW716tTvutGnTysx0X3zxxb5LLrmk2OtY5ts+y8Dfkn2O5557buHjVkcsq/7kk08Wez8///xzseNY/bMMebD99tvPtXgoC5nuyov4zMGSb3y+L+7z+d680Od76mCf794Wxb93t68v2nfiLT7f3U19vicO8PleP8/n+3ysz/fzKz7f8hn+DDWip94gZKg7qCzqDsIt002f7ihj2WvLVFsG2wYoO/vss3XnnXcWPt6rV69i/bh/+eUXLVy40GW6g1mG1LKX69at06pVq3TkkUdWeKAwGwytS5cuLvN57LHHuixpWSx726dPH9WqVdQn8MADD3Tltuxn06b+0Wh79OihuLiiEWibN2/uMu7lsfdkGfvgzHZeXp57T5apTU3191fs3bt34eNWhrp167r3WxZ7PTuGZZKDWd/5hg0bFq7bsTt27FisrOUdsyTLAAe3ArDzf/HFF2vUqFGF2y2DXXLwsuD3Ya8XGA0+8L4tQ24tD1auXOlaL1iZA+egrGPYubb3ZHUlIPBZlPde7JxbFtqy8wF2bcM+yyVLlqhbt26lXsdGsrd+4bs6P1u3bnX1z+pFMFu31wSKsbmNNyzwTyO1fq60Yb5/xOzAFEx/fChNf7L4c6y/cpplnzv5B/YKTCl1xG3S0LvL72cMAABQgKC7Kt0SNKpsSTElpiW5YeEu9i3xI+7q8gPIPWXTOFlzcAusW7RoUWrU8uAA12zfvt01Pw4OlgIaN268x9N37bvvvi7I+uSTT1wzYWtOPWTIEL311luVfEf+kdiDWbBmwVx57D1Z0/GTTz651GPJycmVOq4d04LRmTNnFrsAYOwix66O6U+s717wZ2OvZ5599lkNGjSo2H4lXz/4Ne31TOA1//Wvf7nm2ePGjXNBtL3G1VdfXazLQXnlLuu4uzo/f/3rX3XllVeWesxG0a/sZwmUEvh7CjTJnv22NPN5f4C9bXXp/W1764H+++0P8TcNb7SPP8i2m00rFdz8OyAwRzQAAMBuEHRXpcAcp17uuxsWVJXX37q8INn63zZp0sRlestifbKtL7gF9BVhxznjjDPc7dRTT3UZb+sr3aBBg2L7WfbT+lpbVjcQcFqG2gJ9y5RXlr0ny5TvyXnYnX79+rmssWVlDz744Eofxy6G2HF2xzLLdtFk8eLFro92Zdn5POGEE3Tuuee6dQtw58+fr+7du6sq2Tm3/vN7c84DLTCCz4/VJTsP9j4OPfTQwu22PnBgQSCFyGQXY7as8AfNlrneYNnrgtv570ot+vn3y1jv72sdULuZ1LiL/2bBdb3WRY91HeG/AQAAVCGCbuySBXSWDbXA7K677lKrVq20bNkyN4jVjTfe6Natefqll17qAvOjjz5a27Ztc0GPDbhV0kMPPeSaOFuQasGzDY5mTYjT0tLKfG2bm3vkyJHuNaxJtB3TBuwKNGeuDBt8zJq1W4bVgn4rhzVFtoHE7rnnnkodMzBAmQ3QZoN62fuz8trFCGsyfcwxFZvOxi5gfPrpp+6igDXh3tU815att8yx7WMXLqxZ+I8//qjNmzfr2muvrdDrde7c2bUy+O6779yAdfb5rF27tsqD7r///e/af//93cBpf/nLX9xFFAvCbcC+xx57rELHsPplA//Z9HFW76xVgr33G264wdUTa7Zv83fblHg2aFxZrTNQA9k0VZsWS7WbFjUDn/Wq9NG1/rmsy2KBdyDo7nikdMLjUiMLsjsXHQMAAKCaEHRjl6xvr42ybUGTNce2gLply5auD3cg821BsfWH/ve//+1GybZRri2YLYv1Df/nP//pRpa2ZtD77befmy+8rGbq9toWgNqI3bafrdvo1xYY7g0b3dr6tttFhAceeMA1ae7atasLBveGBXsWtF933XWuf7SdBws0LcCvKOufPWXKFNd/25pk24js5Y3ubuW1c2IXRSzwtEDWmohb8/CKuu2221y23M6JHctGLz/xxBO1ZcsWVSW78PDVV1+5kdStJYA1b7cg2Vo7VJR1hbDR7+1zswsndhw7V3bhwcpr591aGtgFAxsh3y4oIIybgNtc1LEJRXM+W6D86xtSxjppe8HNstTWJNzmfD51vH+eaZPa0B9w2/OtCXjjfaTGXf2Za8tgNwz67Bt18t8AAAA8EmOjqXn14uHKBmeyDJr9kC/ZpNqCS+uT3L59+2L9f71gTYGtrFbGPe1bjegV7fUmnP6GaxobgNEuktkUeiX73/sD6W1SbHxQID1f+u1N//RZFkAXBtPrpNws/yBmfc707zv/M//0W2VJrC0Nu1sacJF/fed2/1Re1t86jmvHNbreAFFcd/LyfZqxZJPWbctSkzrJGti+geJiI2uKQK/eY6TXHYRPvdlV3BjM818rjz/+uMvUrVmzxo1U/eijj5bbF9NOxP333+/mDLZMovXrtUylNa0NsP6e1hT5pZdecse0/p42YrZl9AKDPQEA9qDvtC+/MLitnbVasV/9Q9qxsSiAtqB6+3opd4d04lNS37P8z928VPr6n+UfO3Nj0X3LRu/3F38z8lqN/Uu71Wkm1W1RfK7qpNpSEtlrADXXxNmrNfaDOVq9JatwW/N6yRpzXHcd1dM/00hNFw3vEagoT4NuG6DL+p4+9dRTbgRmG0HZmrlaf1brv1mSBc4WTNuIzdYc2Joen3TSSa4/qvWhNRaE2+jcFpjbVFLWx/XCCy90VyDKGjkZAKJexkbpzxnSlj+lrSulLSsLln/6m3cf/2hhRjp15zrFTX2w/GNlbigeSA+4uCCALgikazXx37dlICNuGnSQjtnFcQEgQlgwetlLP6lkU9M1W7Lc9ifP3bfGB6XR8B6jqcWCF/Ii7Lx6GnRb31zrw2pBsbHg+6OPPtL48eN10003ldr/xRdfdH1CLeVvLrvsMjftlA1cZcG4sQDcBv0KDFxl/WFfffVVzZgxo1rfGwB4LmtrUBD9Z/FgetClRSN1r/pJerWgmXdZbP8C25ObKW/fCxRnGejaTQpugex0k+KzLVggfezejcEAIHp/cE9fskkzN8So4ZJNGtypSY3+wR38viz7W1bfTttm79AeH9q9WY19v9HwHr3O5kdaQBoNrSQ8C7ptHmCb0/jmm28u3Gb9S23O5mnTppX5HBuduWQfTBvNeOrUqYXrBxxwgJ555hk37ZGNKG2jUtvjezv4FgCEldydUvqK4sF0h8Ol1vv5H1/4ufRSwcBjZbE5qQNBt/WNbt5HqttKqtdSqttSqteqYNlSqlP0H1xmUlPlH32h4ugjB0TFj1/vf3DH6X8Lfgz5D+7q+BxtGKXP5qwpFkiU2kdyj1tZBndsqJrIyl6R9zh+6hId26e5mtVNrtIuoNV1wcarbH4kBqTR0ErCs6B7w4YNrv91yamfbH3u3LllPseanlvwfMghh7iRj206Jpu6KnjeXsuQW4d2a35uo2PbY/fee+8u5zK2YN5uAfb8QB9yuwWzdfvStMGo7OalwBh4gfIAFRHt9cbes713+1u274iwny4rL7soe7xujuI+v0Mxmxa57HNMif+S8nxSfrO+/pWUJrKw2JdczwXPvjot5LMg2u7breW+9oXm37deO+miyeWXw6pJftH3YcnvRdQc9mP0x2WbtW7bTjWpk6QBbeuHPECM5Hrz6e9rdc/Hc7Vma9FviGZ1k3TbiK4a3qPyU1tGc72xc/q3134p9wf3o2f2qfJzW1Wf487cfK3ZmqVV6Tu0Kt2WWVq1pWDdlluylJ1bsf93563eogFtyh+UKRwt3ZihyXPX680fV1Zo/3s//sPdUhJi1a5hLXVoVEvtG6WqXSO7n+q21UmO34vP0n/BJhR/k/Y3cef7v+8mm/+7DuvcsEr/Vrz4+6jO74A8j87r3vx/VdF9PRu9fNWqVW7qKWsOPnjw4MLtNvezTS00ffr0Us+xeY+tOfoHH3zgrohZ4G2ZcWuOvmPHDrfPa6+95qZPssHZrE+3zddrUyhZsG5TW5XFBl6zOY9LeuWVV9w0SiWnLbJ5pW2e4KSkpCo4EwCqk11g+/PPP91Ai7m5uV4Xxw1Slpq9XrV3rlWtnWv8yyz//dTsDZrb/BQtaHac27XOjpU6Ym5R66Dc2CTtSGyoHQkN3G11Wn+trVcwP7UvX3H52cqLq5kjtOf7pEVbY7Q1R6qbIHWs6xPJw73zy8YYvb00VunZRScyLdGnk9vlq09DJjKpzPkcPz8wA0Rw5fSfy4v2Cd15rc6/j+qsN/a+xv4Up/RsWyvrDfmUliiN2Tevyt5vRT9H+7W8I0/avFPatDPGLTfbMrtofWtORQoVCB12r1Utn7qn+dQtLV9t60hxYfYdaBd6l2yTft8Uq9mbY7Qua88KmJbgc3U4fxfno26CT01SpCbJPjVOKbrfMEmKi62ev0n77HPy/Z//jlz/cuGWGH24YvcX7g9tlqcWtaTEWCk+VkqIKVjG+gqWUnyMfxm42edcVuLfi7+PUH8HZOdJ23Lsb0famh2jhVulr9fs/ryO7p6nzvXC4/+tzMxMnX322bsdvdyzoNual1tA+9Zbb7l5gQMsME5PT9d77723yyl/Nm7c6EYmt8y2zbn8+++/u8dat27ttl1xxRWF+9vcydbnu7wMelmZbjuOZeNLnjzLnNu8xo0bN1bDht42+7GPzubNtrmvGZkdFRXt9ca+O+wCXocOHaov022jf29dqZhNi12W2tews3ztDvY/tm6OEp49pNyn5vc9T3nH/Nu/krtTMb9PUF5ae83KaKiVObXVpG5ytWQrA1dzJ02apKFDh4Z0ChavsodeZIGrS3nZkcC7C2V25PtF6/XFtJk6YnB/7d+xccjPaXV8jvYahz34dbE6WpK99hfXHKSkhLga+/dRVfXG/t/JzM7T1qxcbd2R419m5WhbVq62FKzb/YXrtuubhUGzGpSjc5NaalgrUQlxsQW3GP8yPlaJgftxdj/4seDt/vtxMTG666O5St9RfqYqKT5Wresna/XWncrYWdSysjzJCbFqUS9ZLdJSSiz9t8a1kzR03FSt3bqzzGyeSYiNUY5FWEHqpcTroI6NdMg+DXVI50ZqVNubxM+2rBx9s2Cjvpi3Xl/N31Ds3Nm5HtiugQ7r0kjPfL1EG7Znl/kerf40q5ekL689RPk+n1Zs2qElGzO0ZEOmlmzI0JKN/qU9vzzxsTFq0yDFZcNddrxhqv49eaE2ZZT9WcYU/E0+f0F/Zbi6mKNtO3K1JStHW3f469/Wgvtu6epkjrYUrOfYFYZqZPWu2C0hTrl5+Vq2yZ9k3JXLD22vvq3TVDsp3rUUsKX/Fqf4klcqQvAdkJ/v0+YdOdqwbafWbd+pDduytX77Tq3ftlPrt2e75QZb357tzntlPHRaLx3Xu3lY/M6xuLFRo0bhO2VYYmKi+vfv75qIB4Jua/Zp66NHj97lc61ft2XJ7cRMmDBBp59+erGrDSXnHrYf1rtqRmsZ67Ky1nayS55wW69fv74LyO117MKBV4GLvSe7eGEXDKJxvmVUTrTWG/ejLzPT/e3a33BVztFdqi9gs1jFffuQtGmxtHGRtHmJf17qgH1HSp2P8N9v3FmKT/H3q27Y0T/4mFt2dMvYOs0VG/iOSUjQxORhGvum9eVa6llfrrK+G6uyL1dZ/8HbD1TbTh+5ytXPez+Zt8vmevb40b1bVmlwWrpf7qyQn9Oq/Bwzs3Nds+CV6VlauXlHwX3/bfG67dqQUX5AYCzo73nXZDWolahGtRPVsFaSGta2+0lu3ZYN3S3RBWK2TE2MD5u/j93VG3Pb+3O0cUeuthcG0/6gZUvh/YIAe0eOcksEkXtjwboMLVCGqoM1GV+4PrNw3YJ9C6RbWjBty/p2P1kt01JdUG2f9+5+F955fA/XFNj28pUVyJzdT/u2ra+v52/QlHnr9M2CDe6cfjR7jbuZni3r6vAuTXRYl8bq2zq0FwhXbMrU53+s1eQ/1un7xRuLfZb1UxNcOY7s1lSH7NNIdZL9/ze0blBrl+9xzHE9lJyU6O53aZGkLi3SSr2uveelGzK0eMN2LV5vywy3XLJhu7Jy8rV4Q6a7ad7u34OVYe22nTr60e8qfR7sFNdNSVDd5AR3vu3CwO7s166+aiXFa2dOvnbm5rn65L/lFWzz37f3EyywX2U88dWSch9LSYhT7eR41QkE5IVBeYJbLwzSk+NVKzF+lwPimZve+V1fL9yojRZMb9+pdVv9AfWe/L0nxceqSd0k9z1o5/WHpZt3+5zmabVCevF/T37nVHQ/zzLdgSnDLLP99NNPu7m5bcqwN954w2WkrW/3+eef74Jrm5vbWJNzm5+7b9++bmnNwpcsWaKffvpJaWn+P1abk9tGNLdjWvPyn3/+WZdccokuuugiN51YVUxybqfMmqZaRt5LVg5rVm+DyUVjxhKVE+31xr4rrItIpd67XbzbtsofTBfc1iydo22r5uurnO66J/c8t1uHuj59kV1iHInYhKLAuvNQ/5zUwcetwAWQ8gYXCbyTUA4uYj/Apy1cp8++ma5hBw8KycA09hoHPfBFuQPw+LMjyZr69yOqPDj04ryGauAmyzKs3Zal5RsztWxTpr5buEHvzlq12+f1allXbRrUUt2UePej0v24dD8w492yXsGPzcDjybvI4HpxTvfkNe17cGNGdqlg2q1v8S83Z1Z/H/TUxDgXfFuAXjw4T1T91ETd9eEcbdpFsG+ZvOcu3M/1G96RnacdOQW3bPtR779vGWdbZhU+nl/4uF1osHW7n56ZXeXnwLKTrh6VqFtWn2y7veZrP6zY7XGuGbKPOjSupZy8fHfLzvO59+zWc4u2BR5367kl1vN8Wp2+QwvWbd/t6112aEedOqCVWtRLUUpiXLVfILIM5y9/pmvKvPX6ct46zV7pH3sowM7dwZ0bueD3kH0aq3GdpL363rF9Zq1I1+Q/1rpge/7a4ueoY+NaGtKtqQu0922TVm72NFQXM+07zvrO+wNxf0BuFwPmrtm22+cmx8e6i11l1b/g7756wY8XrNdKjCv87RD4/8r6Uvuq4P8r+07KzisIwoMD9JyioHzWis16YOLurzD0aFHXXazfvtOfwd++M6dUUF8d7AKV1cXgW5M6yf77tZP8gXadJHcBIFTndU9ZQvfjjz92M2XtSaZ7V3FjWATd5rHHHnP9ry2ItWD6kUcecXN2m8MOO8xN+fX888+7devrbdOEWfPu2rVruxPyj3/8wzUzD7Bms7fffrveeecdrVu3zj121lln6Y477nDZ9ao8edbU3MuBYey1v/76azewXCiv9iCyRHO9sfe72ybl+Xn+KbIsqI5Pktoe4N+enSH9s0PxjHWQqXk9dG7Ore6+/TdwffxrOnxAL3Xvsa/UsINUr40Ut+eNi+w/IPthbJmk4x6b6pplqZr/I6rKH072X479kF+7NSvottP9gJq7eqt+Wr77i5n2w8d+AKUm2ZX4OJdFsAxhraQ4/7JgW+F6wdKu3qcW7h/nruJb4HjEg1M8CfT35pxaUGTZp2UbM7V8U9Ft2cYMrdi8o8KDNe0Ny06UFZTXTo7Te7NW7bIprv0Ye/ycfV1zVPuxZT8Q7fTa0n57xQZt8z8etC229ONWr457dKrLZO0qw2MBgp1zC7ArkkWyOtOyIJvZIiibacHhmPfn7Pb5T527rxsUyppXbsywDFC2ywJttCaX27MLl7atslktr/VuVU9dm9UJuijjD16KrRcENdb0elcXPKv7B/e0RRt11rPf73a/V0ftH5KRxCt74c32D2TBv56/3rUmCNarZT2XAS+ZBd/V987BnRu7jLoF2l/MXecuSgXY8y1jGwi02zeqFfL3WBM+y8CFPpWTza/qi4t78/dh/ydk7MwNCsT9zedLrVuzetsvK9dl8ityUWpEz2aFF3sCgbVdKLQuHDXhvEZN0B2OKnryvFaZigFEer3Zo//gLcP8w3+KZa61eakbqdvpeIR03jtF+/+rk7Rjs5TWVr4GHfTmkgT9ntVYy3xNtcjXXCt8xfs1WbO7m47u6s86uWxTYJm7ywxTYYYqO89d+d4TaSkJ7upxWkqi0lITCm4F9wPbUoK2pSa4YKS8H8J7kj2092A/BiyIDgTUFkxbc7Pg+3v6nsLByfu2VLdmdf3N8gqa3/mX/iZ5gaZ4FfkxWZFzOrxHM/ej1wXTBYG1Bdgu0N6U4c7x7jKKFii2aZDqguPP/1i323JdflhHlykNNAcuaiLs79Po1nfkuB9kkfDLwaq8vd9AU+HC4LpeIMhOcYFiWUKR5bJ+ptYHsnhwXhSYz12zVYvW7745q2WN0mr5/67dLbFoaReZAtvtwlNy4LGgx227rc9fu023vDO72gPS6vzB7XVWrSpYFtyy0pYFnzK/dBbcvuMtoG6QmqAXpi3b5XdGcJNg+147rEsTDenWRIft00T1UsP794JXn2V1d02qzr8PLy9KTfSoyxdBdzUj6EYki+R6E/wlnaBctY5Zp361NukvPaRuSRv8QbVNm3X8I0VPeqC9tGNT8QPFJUr120ttByv76H+7gNGOuXnNMi3NStXqbbmavXKLG6wpEiTGxxYE4gXBeMF9y1C9PmOFC7J29dxWaclavy17l/uVlem0QeBsAKimdZPdza7C/2dq+X3RAh48vY86N6ntMqkW6FuwkllwBd+azmZk5ypzp3+ZEdgW9Jg9z9ZDkVm0LLs/ME8oNYiNbUtNitML3y3d5eAx9uPXBnrK3E1zQAuu2jRMdYG1Lds2qOXut22Y6n6cBJp8VvWPUWvaaZ91eX14f1iySZ/OWbvb41hGxAI8G0jJrn+5aQxt2ruCpX+9aJuvYGnvJ3A/8HhFnTOojY7p3Vyt0lLVtF6SkuIr31S4urMx1f0D2MuAtDp/cHuZVQuFQBbcmqF/U0YWfFdsYLIh3Zq5QHu/9g0qnan0ilefZXVl86v778Pri1J51XxeQx10ezaQGgCE4j/bGOXrvcQ71DNmieJifJL93vglaEcbqKyAZaCzup+ljKxsrY1voRVqpoV5TTU3o7ZWb8vR6l+ztOG7T/Yqq9eteR03uqpljgJZJZdhKpGFKswwBa0H7tv2n5dv1lnPlp5KsaT7Tuqptg1rKT0zR5szs10wFOibadu27Ci6b9sts2HnwQZ9stuesue6gWyCgs6m9ZLVtE6y+8/Ysu7NCoJq/83f/KysYMf+g/3ot9W7/Q/+xL5VM+CXZYi+mr9eF7/w4273HdqtqQumLVgONMlzt4JRlwPZe7sAYLfdZaJ3Wa58n7tZJrZ53WS1Lgik/cF1QWDdINVdGKnI2AR2ruzH2K4HNepe4XMaW9Avt7wscI8W9SoUdD9yZr8qy45MW7ShQn8fx/ZuUWWvaT9u7Ud8yR+/zUIUHNoPTvthvbu/D9uvKlR1vdkTdu6Gdm8W8nEkvPgcQ82Ck1P7t3K3QBb8pe+XVWhchwdO6a3BHRuppvLqs7R6GYruB7v7+wh1QOrld4AX5zXUCLoBhFTIrlTm5UgrZ0qLv1L+ttUaO/s49x+CT7HKVrwLuDN8SVrma6alvqZaHddcDVt31cK8Zvr6sanuP2RrvunzHVjiwPYfdVapbK792PXfUtzSmoGP/7ZoBPHy3HFsjyr5T2Ng+4YV+sF9xn5tKnx+A01aLfj2B+T+QD1w/8elm/TlvPW7Pc7owzvqpH1buaDaMro15T94ywRb88mKnNenzuu/y9e1gW4sAA/0jwv0kbMBbILXf/tzi6Yu3LDbst0yopvOH9x2l4OVheuP0eoODvfk76MqX7M6f/x69QPYy4DU3seg9g208Q+fW4Yyw1Wdn2N1su+4Ae0auDEMKhJ0V+bCa7ipzgs2XqqugDTSLkp5iaAbQM1oAmWjrq+crax5kxW79GvVWv294nMD/RtjlJE12IY9cmu35lysLb5aWqv6RT9HrZv2gsDBtpQbUNt/JDanarOC4NpuZU0BYxcTPpm9pkZnnew9BZo+t7JTVUZz1ooE3Qd2aqyOjf3nvqb9B19V59Uy90m1beTpXc+da+e0IkG3DYRUVQF3NGRHvMzIVGc2xosfwJEakEZ6Vi2YfWZVuV+4q84LNtEgWr4DQo2gG0BIlDdYlAWptt1+ONqXuGVZbcAoG0DI5r31DxrkH0CocDChjJ26MuNRnRbzhVKCjrXJV1vf5ffUt/k9lK+ivmfzfa3LLJP1Uzt0n8a7DagrIhqyTl5kLL34Dz7Ss8DRkh2JloyMFz+AIzkgjQZef++g5uM7YO8RdAOocpYFth++Zf3nHth2+cs/ub7SwfvU03YNjp2jA2Nn65TY2RqVc50W+Vq6x36M66hj46fqR183/ZLYVwtrD9D2el3UoE6ym8dy+y+7bzp38UEdqvQ/jUjPOkVL9jDSs8DR1MwzWjIy/ADGnoim7x0gXBF0A6gSlqH+beUWN6q3DU5V3rzHATbicJKyNSB2noYkztEBsb+rc/4ixQb9HHig70Zt7Hm8GtVOUuPkQcqvPVYHpabq4DKaes9YusmTq/iRnnWKluxhpGeBo6mZJwEpEN3fO0A4IugGoogFp9OXbNLMDTFquGRTpbNO67ftdMF1IMi226rdBNkmVvlKVrYy5e839sQBGTryp/v9DwZmR2rcVepwmNT+UA1od6CUXC/sr+JH+o/8aBmYpjpFS0YWQPjgewfwDkE34KHqnIOw+KBmcfrfgh8rNKjZuq1ZBcH11sIge83WsgPsDo1qqWfLeqqbHK+Xpi9325pro46M+0kHxc7W4Njf9UrekXog9yz3WO19DpEWt5XaHlgQaB8i1a3c1Xau4ocWA9NUvUi/WAMg/PC9A3iDoBuIhJG9q2BQs+E9mrm5hYMz2LYsawoRa91tAbaNsGxBti27t6irOskJbpTxvHVz1Wr2hzogZ5p6xy4p9tx+sQsLm3sP2Ke11PXXKnufXMUHAABAuCHoBjxQkSC4qgLvigxqdtVrs9y0UTaKeEkWr9p0UD1LBNjlzsfsy1fc8yN0ad4ma0+ufF+MfvTtoyl5fd0o47N9HSJqAC4AAABgVwi6gWq2uyDYwtAx7/+uPq3TlJvn087cfGXl5LnlztyCZU7w/cBjxe8HnrMqPXO3g5r5n5PtAuxOTWoXBteBADs1sYyvirwcaek30h8fSqt/kf7yuT8FHhsn9ThRSl+h2XUP1o2zW2nO1uSQZ/MBAACAcETQDVSzL+et22UQbIG3NfMefP8X1Vquq4d01iWHdCg7wA7IzpAWfi7N/UiaP1HK2lL02KqfpZb7+u8f85ALwHtK+uDY6uu3DgAAAIQbgm4ghHLy8jVvzTb9vCJds5ana9aKzVq0PqPCz09JiFNSQqyS4u0W518mFN1PtsfdYwXbSuxrj6/askPPfbt0t681qH3DXQfcM5+XPvm7lBt0wSC1kdR1hNT1OKlpj6LtQVN60dwbAAAA0YygG6iikcR9Pp/+3LxDsyzALrjZYGTWdLsyXh01SIM7NlJVvK+Js9fs2RzW6SukeR9LrQdKLfr5tzXo6A+409pK3Y6Tuh7rf9yakwMAAAAoE0E3UMmRxLdm5ejXFVtc9joQZG/YXnogMps+y/pn9y24WX/pEx//tgJBcNVkhys0h/Wx3RS3YZ4094OCPtqz/A8M/GtR0N1msHTpVKlpz2KZbAAAAADlI+hG1KvISOJHdmtarJn4L3+ma9H67TY7VjHxsTHq1rxuYYDdt02a2jespdgSGfPdBsFVPLJ3eXNYt60bo/HtJqvDl7dLmxYVL0mb/aXmfYo2xcVLzXpVWZkAAACAaEDQjahWkem0/vbqz25U7525pfdq3SBFfVr5A+x+bdLUo0U914+6skFwsxCO7O3msN6nvn6Z9YPe/W2zhh1szdcbK+6RG6UtK6S4RKnDYf5m412Olmo3qfIyAAAAANGGoBtRzfpw7246rZw8f7BdJzm+KIPdOs01GW9UO2nvguDuzUI/snfmJmnBJNdHO27hZPWLjdOfXf+tQfZacbHS4bdK8YlSp6FSct2qfW0AAAAgyhF0I6pZsFsRt4zopr8c1L5UM/G9FbKRvTctkeZ+KM37RFo+TfIFDeZWq4lSd64vWu97VtW/PgAAAACHoBtRy/povzpjeYX27dWyXpUH3FUqP8+GT/f3uzazXpG+/mfR4zb42T5HSV1GKLdJT2V8MtGzogIAAADRhKAbUWfOqq169IsF+mT2mt3uW+Z0WuFi53Zp0Rf+bPaCT6XjHvZP5WVs7uw/Z7gg2wXb9dsWPS8nx7MiAwAAANGGoBtR47c/t+iRLxZo0py1bt1mvRrRs7kbAO3ej/5w26pjJPG9smWlNP8Tf6C95GspL2iKsoWTi4Jum+br/Pc8KyYAAAAAP4JuRDybP/uRyQv0xdx1hcH2sb1b6G9HdNI+Teu4ba3qp1TrSOKVsuVP6d89im+r317qeox/tPHW+3tVMgAAAADlIOhGxJq5bLMenrxAX8/3DxpmyeoT+rbUFYd3Uqcmtb0ZSbwicrKkpd/4s9mWez/23/7t9VpJTbpLSXWlLv7+2Wq0j/8qAgAAAICwRNCNiGOBs2W2py7c4NYtcD6pnz/Ybt+oVvWPJF4RGRukBZ+5ab208AspJ8O/PSFVGn6flJDiX79kihRf+WnKAAAAAFQvgm5EBJ/Pp2mLN7pg+/vFm9y2+NgYndq/lS4/rJPaNExV2HrzAun3d4v3KK/T3N9kfJ+jpdigP1MCbgAAAKBGIehGjQ+2LaNtwfYPSze7bQlxMTptQGtdflhHtaofhsG2Te1lt9hY/7r1xf79HalZb3+gbbfmfWk2DgAAAEQAgm6Erbx8X7l9rC3YnjJ/vQu2f16e7rYlxsXqzIGtdemhHdUiraA5djixQNv6aU+5XzrwKqnXqf7t/S/wD4aW1trrEgIAAACoYgTdCEsTZ68uNZp483rJuuPY7kqMj3XB9i9/bnHbk+JjdfagNvrrIR3diONhGWzP/9QfbK+e5d827fGioDshmYAbAAAAiFAE3QjLgPuyl34qNme2sQD8spd/KlxPSYjTufu30ahDOrhMeFgG2ws/l768T1pVUO6EWtLAUdIBV3pdOgAAAADVgKAbYdek3DLcJQPuYNbA3ALtSw7poEa1w3hgsY+ulX4cXzQK+X5/8Tcrr9XI65IBAAAAqCYE3Qgr1oc7uEl5WSwgP7xLk/ALuC2znZ8nxRX8WXU9Vpr1qrTfxdKBV0u1G3tdQgAAAADVjKAbYcUGTavK/aot2F7ytb/PdofDpMNu8m/veIR0ze9SLY/m/gYAAADgOYJuhI2V6Tv0xg8rKrRv2PThXjrV32d72bf+9Y2LpIOuleIT/VN+EXADAAAAUY2gG57blpWjJ6Ys0n+nLlF2bv4u97X+3DZCuU0f5qll3/mD7aXf+NfjEv1Tfx10jT/gBgAAAACCbngpJy9fr81YrnGfL9DGjGy3bVD7BjqiaxP945O5bj14QDX/DN3SmOO6F87X7YlvH5Ym3eG/H5sg7Xu+dPC1Ur1W3pUJAAAAQFgi6Ea18/l8+vyPdbr/kz+0eH2G29ahcS3dcnQ3HdmtiWJiYtS2YWqpebotw20B91E9m1d/oXOzizLY3Y6Tvrxf6nOmdPB1zLENAAAAoFwE3ahWv/25Rfd+PEffL97k1hvUStQ1QzrrzIFtlBAXW7ifBdZDuzdzo5nboGnWh9ualFd7hvvPmdKU+6SkutJpz/m3NeggXTdXSkmr3rIAAAAAqHEIulEtVqXv0P99Ok9v/7zSrSfGx+rig9rrssM6qm5yQpnPsQB7cEePBiJbacH2P6QFnxU1I9+2VqrT1L9OwA0AAACgAgi6EfJB0p4sGCRtZ8EgaSf1a6nrhu2jVvVTFXbW/CZ9cY80f6J/PSbO34z8kOuLAm4AAAAAqCCCboREbl6+Xv1hhcZNml84SJo1D7/tmG7q3SpMs8TzP5NeO1vKz5FiYqXeZ0iH3CA17Oh1yQAAAADUUATdqPJB0r6Yu073ffyHFgUGSWtUSzeP6KYhBYOkha1WA6R6LaXG3aRh90iNOnldIgAAAAA1HEE3qszslVt070d/aNrijYWDpF09pLPOKjFIWljJ2CClNpTsYkBqA+miz6TaTfzrAAAAALCXPI+EHn/8cbVr107JyckaNGiQZsyYUe6+OTk5uuuuu9SxY0e3f58+fTRxYkHf2yArV67Uueeeq4YNGyolJUW9evXSjz/+GOJ3Etny8n2atmij3pu10i1tPXiQtGvfmKXjHpvqAm4bJO3SQztqyg2H6fzB7cI34F74ufTYAGlmwajkxvptE3ADAAAAiIRM9+uvv65rr71WTz31lAu4x40bp+HDh2vevHlq0qRJqf1vu+02vfTSS3r22WfVtWtXffrppzrppJP03XffqV+/fm6fzZs368ADD9Thhx+uTz75RI0bN9aCBQtUv359D95hZJg4e3WpObOb10vWjUd11cJ12/Sfb4oGSTuhbwvdMLxLeA6SFpCfL33zoPTlvdYgXvr1DWnfC6TYML04AAAAAKDG8jTofuihhzRq1ChdeOGFbt2C748++kjjx4/XTTfdVGr/F198UbfeeqtGjBjh1i+77DJ9/vnnevDBB10wbh544AG1bt1azz1XlL1s3759tb2nSAy4L3vpJwtNi7EA/JrXZxWuD2zXQLce0019WofpIGkBO9Kldy6V5n/iX+9/oXT0AwTcAAAAACIr6M7OztbMmTN18803F26LjY3VkCFDNG3atDKfs3PnTtesPJg1H586dWrh+vvvv++y5aeddpq++uortWzZUpdffrkL7stjx7VbwNatWwubs9stXAXKFqoyWhPyO9//vVTAXXIu7YdP661hPfyDpIXz+dK6OYp/a6RiNi+RLy5JeUf/S74+Z7tkt8K53DWs3iByUXdQGdQbVBZ1B5VF3UF11ZuK7hvjs+GmPbBq1SoXEFvT8MGDBxduv/HGG12wPH369FLPOfvss/XLL7/o3Xffdf26J0+erBNOOEF5eXmFQXMgKLdm6xZ4//DDD7rqqqtcFn3kyJFlluXOO+/U2LFjS21/5ZVXlJoaxs2kQ2zBlhg9Nidut/uN7p6nzvU8qUYVlpi7TUN+v04J+VnKTGykGe3/pi2ptIAAAAAAUDmZmZkuRt2yZYvq1q0bGaOXP/zwwy5jbf25Latqgbc1Tbfm6AH5+fkaMGCA7rvvPrdufb1nz569y6Dbsu0WpAdnuq2J+rBhw3Z58rxmV1YmTZqkoUOHKiEhocqP/8Gvq6U5v+12vw49+mpE7+YKd7ENVyt/2VQlnPi0DrQRy6NUqOsNIhd1B5VBvUFlUXdQWdQdVFe9CbSQ3h3Pgu5GjRopLi5Oa9euLbbd1ps1a1bmc2xQNMtyZ2VlaePGjWrRooXr+92hQ4fCfZo3b67u3bsXe163bt00YcKEcsuSlJTkbiXZya4Jf6ihKmfztFoV3i8sz9O2tVJOptSgIKN96PWS71rFxu4+ex8Nakr9Rvih7qAyqDeoLOoOKou6g1DXm4ru59noUYmJierfv79rIh6cpbb14ObmZbEm5NY0PTc31wXT1sQ8wEYut9HPg82fP19t27YNwbuIbAPbN1Cj2onlPh5TMIq57Rd2ln8vPX2I9No5UnaGf5tNBUbADQAAAKAaedq83Jp0W5Nvaw4+cOBAN2VYRkZG4Wjm559/vguu77//frdu/bxtDu6+ffu6pfXFtkDd+oEHXHPNNTrggANc8/LTTz/dzfv9zDPPuBv2zPasXBdYlyWwfcxx3d1gamHDhiiY8Yz06S1Sfq6UkiZlbpISK5a1BwAAAICICbrPOOMMrV+/XnfccYfWrFnjgumJEyeqadOm7vHly5e7Ec0DrFm5zdW9ePFi1a5d200dZtOIpaUVTVO133776Z133nH9tO+66y43XZgF8+ecc44n77Gmys/36erXf9b67dlqWCtR8bExWrutaIT3ZvWSXcB9VM8w6sudnSl9cJX02xv+9R4nS8c/KiXV9rpkAAAAAKKU5wOpjR492t3KMmXKlGLrhx56qObMmbPbYx577LHuhsp75IsF+nLeeiXFx+qFiwaqW/O6mrFkk9Zty1KTOv4m5WGV4d64SHrjfGntbCkmThp2t7T/5f4m5QAAAAAQrUE3ws8Xc9dq3OcL3P17T+qlni3rufuDO4bxiN+f/N0fcNdqLJ32vNTuIK9LBAAAAADeDaSG8LRsY4aufm2Wu3/e/m11av9WqhGOf0Tqcoz0168JuAEAAACEDYJuFMrMztVfX5yprVm52rdNmm4/tvjUa2HFBkeb9UrRet0W0lmv+JcAAAAAECZoXg7H5/Pp5rd/09w129SodpKeOKe/EuPD9JrM6l+l18+V0pf5RyXvXjRlHAAAAACEE4JuOM9/t1TvzVrlBkd7/Ox+bnTysDTrVenDq6XcLKl+O6l+e69LBAAAAADlIuiGG5X83o/+cPdvGdFNgzqE4YBpudnSpzdLP/zHv955mHTyM1JKfa9LBgAAAADlIuiOcmu3Zunyl39Sbr5Px/dpoYsObKews3WV9MZI6c8Z/vVDb5IO/bsUNIc7AAAAAIQjgu4olp2b7wLuDdt3qmuzOvrHKb0UE47zWq+Y7g+4k+tJJz8r7TPc6xIBAAAAQIUQdEexez6ao5nLNqtOcryeOre/UhPDtDr0OEnaulrqcpTUoIPXpQEAAACACgvTKAuhNmHmn/rftGXu/rgz+qpdo1oKKxkb/SOTJxQM6Db4cq9LBAAAAAB7jE6xUWj2yi265Z3f3P0rj+ysI7s1VVjJz5cmXCw9e4S0bq7XpQEAAACASiPTHWXSM7N12csztTM3X4d3aayrj+yssDPjGWnxl1J8ihTDdSEAAAAANRcRTRTJy/fpytdmacWmHWrTIFXjzuin2NgwGzht3R/S52P894fdLTXex+sSAQAAAEClEXRHkXGfz9fX89crOSHWDZxWLzVBYTcX99ujpNwsqdMQab+/eF0iAAAAANgrBN1RYtKctXr0i4Xu/j9O7q3uLeoq7Hx5r7TmNymlgXTC41I4Tl8GAAAAAHuAoDsKLF6/Xde+Psvdv+CAdjqxX0uFnaXfSt8+7L9//CNSnWZelwgAAAAA9hoDqUW4jJ25uvSlmdq2M1f7tauvW0Z0U1hKay21PUBq0F7qdpzXpQEAAACAKkHQHcF8Pp/+PuFXzV+7XY3rJOnxs/dVYnyYNm5IayON/EDKy/a6JAAAAABQZcI0AkNV+O/UJfrw19WKj43Rk+fsqyZ1kxV2MjYW3Y+NkxJSvCwNAAAAAFQpgu4INW3RRt3/yVx3//Zju2tAuwYKO1tXSY/1lz6+UcrJ8ro0AAAAAFDlCLoj0OotOzT6lZ/cvNwn9Wup8we3VdjJz5fevVzasVn6c4Y/yw0AAAAAEYagO8LszM3TZS/9pI0Z2erWvK7uO6mXYsJx6q0ZT0uLv5TiU6STn5XiwmzOcAAAAACoAgTdEeauD+Zo1op01UtJ0NPn9ldKYhhmkNf9IU0a478//B6pUWevSwQAAAAAIUHQHUHe+HGFXp6+XJbYHndmX7VpmKqwk5stvT1KytspdR4mDbjY6xIBAAAAQMgQdEeI3/7cotvene3uXzNkHx3epYnC0pf3Smt+k1IbSsc/JneFAAAAAAAiFPN011A2SNr0JZs0c0OMEuas1T0fz1N2br6GdGui0Yd3Uthq3ltKricd94hUp6nXpQEAAACAkCLoroEmzl6tsR/M0eotNs1WnP634Be3vXHtRD14el/FxoZx9rjnKVLHI6SU+l6XBAAAAABCjublNTDgttHJ/QF3ceu3Z2vaog0KS1lbi+4TcAMAAACIEgTdNaxJuWW4feU8bvlte9z2Cyuz35Ye3VeaN9HrkgAAAABAtSLorkFmLNlUZoY7wEJte9z2CxtbV0kfXiNlrJdWzvS6NAAAAABQrQi6a5B127KqdL+Qy8+X3r1MykqXWuwrHXqj1yUCAAAAgGpF0F2DNKmTXKX7hdz0p6TFU6T4FOnkZ6S4BK9LBAAAAADViqC7BhnYvoGa10t2fbfLYtvtcdvPc2vnSJ/f6b8//B6pUWevSwQAAAAA1Y6guwaJi43RmOO6u/slA+/Auj1u+3kqd6f09iVS3k6p8zBpwMXelgcAAAAAPELQXcMc1bO5njx3XzWrV7wJua3bdnvcc/m5UvM+UmpD6fjHpJgwnjccAAAAAEIoPpQHR2hYYD20ezNNW7hOn30zXcMOHqTBnZp4n+EOSKwlnfi4tH2dVLuJ16UBAAAAAM+Q6a6hLMAe1L6B+jfyuWVYBNw5WZIvaI5wAm4AAAAAUY6gG1Xngyull0+Ttq31uiQAAAAAEBZoXo6qMXuC9OvrUkyslL5MqtPU6xIBAAAAgOfIdGPvbVkpfXiN//4hN0itB3pdIgAAAAAICwTd2Dv5+dK7l0lZW6QW+/qDbgAAAACAQ9CNvTP9KWnJV1JCqnTys1JcgtclAgAAAICwQdCNyls7R/r8Tv/94fdKjTp5XSIAAAAACCthEXQ//vjjateunZKTkzVo0CDNmDGj3H1zcnJ01113qWPHjm7/Pn36aOLEieXu/49//EMxMTG6+uqrQ1T6KJafI9VrKe1zlNT/Qq9LAwAAAABhx/Og+/XXX9e1116rMWPG6KeffnJB9PDhw7Vu3boy97/tttv09NNP69FHH9WcOXN06aWX6qSTTtLPP/9cat8ffvjB7du7d+9qeCdRqHkf6a/fSCc+KcWEwTzhAAAAABBmPA+6H3roIY0aNUoXXnihunfvrqeeekqpqakaP358mfu/+OKLuuWWWzRixAh16NBBl112mbv/4IMPFttv+/btOuecc/Tss8+qfv361fRuokReTtH9pNpSagMvSwMAAAAAYcvToDs7O1szZ87UkCFDigoUG+vWp02bVuZzdu7c6ZqVB0tJSdHUqVOLbbviiit0zDHHFDs2qsCOdOmJ/aVpT/hHLgcAAAAAlCteHtqwYYPy8vLUtGnTYtttfe7cuWU+x5qeW3b8kEMOcf26J0+erLffftsdJ+C1115zTdWteXlFWCBvt4CtW7cW9h+3W7gKlK06yxj30XWK3bhQvhnPKLf32VJirWp7bdTceoPIQN1BZVBvUFnUHVQWdQfVVW8quq+nQXdlPPzww645eteuXd0AaRZ4W9P0QHP0FStW6KqrrtKkSZNKZcTLc//992vs2LGltn/22WeuqXu4s/daHVps/l77LX1L+YrV1MbnafPnX1XL66Jm1xtEHuoOKoN6g8qi7qCyqDsIdb3JzMys0H4xPp/PJw+bl1tQ+9Zbb+nEE08s3D5y5Eilp6frvffeK/e5WVlZ2rhxo1q0aKGbbrpJH374oX7//Xe9++67bmC1uLi4wn0tC24BujVdt4x28GPlZbpbt27tMvF169ZVuLIrK1Yphg4dqoSEEM+PnZ+n+Id7KCZzg/IOul75h94U2tdDZNQbRBTqDiqDeoPKou6gsqg7qK56Y3Fjo0aNtGXLll3GjZ5muhMTE9W/f3/XRDwQdOfn57v10aNH7/K5lsVu2bKlOzkTJkzQ6aef7rYfeeSR+u2334rta5lwy4z//e9/LxVwm6SkJHcryU52TfhDrZZyblkrZW6QYuMVd9jfFRcf/ucFu1ZT6jfCD3UHlUG9QWVRd1BZ1B2Eut5UdD/Pm5fbdGGW2R4wYIAGDhyocePGKSMjwwXK5vzzz3fBtTUBN9OnT9fKlSvVt29ft7zzzjtdoH7jjTe6x+vUqaOePXsWe41atWqpYcOGpbZjD2xe5l/WayXFJ3pdGgAAAACoETwPus844wytX79ed9xxh9asWeOC6YkTJxYOrrZ8+XLXLDy4WbnN1b148WLVrl3bTRdm04ilpaV5+C6iQPpy/zKtrdclAQAAAIAaw/Og21hT8vKak0+ZMqXY+qGHHqo5c+bs0fFLHgOV0HqgdOy/pdSGXpcEAAAAAGqMsAi6UQM07Oi/AQAAAAAqrKjdNgAAAAAAqFIE3aiY39+Rln4r5WR5XRIAAAAAqDFoXo7dy82W3rTR5H3SdfOlhGSvSwQAAAAANQKZbuze1j/9AXd8ilS7idelAQAAAIAag6AbFZ+jO62NFBPjdWkAAAAAoMYg6MbupRcE3fWZoxsAAAAA9gRBN/Ys0w0AAAAAqDCCbuxe+nL/Mo1MNwAAAACEfPTyvLw8Pf/885o8ebLWrVun/Pz8Yo9/8cUXVVU+hAOalwMAAABA9QXdV111lQu6jznmGPXs2VMxDK4V2YbcKa2fJ7Xs73VJAAAAACDyg+7XXntNb7zxhkaMGFH1JUL4aXeQ/wYAAAAACH2f7sTERHXq1KkyTwUAAAAAIGpUKui+7rrr9PDDD8vn81V9iRBeNiyUZr0qrf7F65IAAAAAQHQ0L586daq+/PJLffLJJ+rRo4cSEhKKPf72229XVfngtUVfSJ/cIHU9VjrzZa9LAwAAAACRH3SnpaXppJNOqvrSIHxHLme6MAAAAAConqD7ueeeq8zTUBMxXRgAAAAAVG/QHbB+/XrNmzfP3e/SpYsaN268N4dDONocyHS38bokAAAAABAdA6llZGTooosuUvPmzXXIIYe4W4sWLXTxxRcrMzOz6ksJ79C8HAAAAABCG3SPGzdOkydPLly/9tpr9dVXX+mDDz5Qenq6u7333ntum41sjgixI13K2uK/T6YbAAAAAEITdB988MEaNWqUXnzxRbc+YcIE/fe//9XRRx+tunXrutuIESP07LPP6q233trzUiA8pS/3L1MbSUm1vS4NAAAAAERm0N2/f39Nnz5dr7zyilu3JuRNmzYttV+TJk1oXh5J6reTzpkgHfOg1yUBAAAAgMju022DpH388cfu/uDBgzVmzBhlZWUVPr5jxw6NHTvWPYYIkVxX6jxE6nGi1yUBAAAAgMgfvTwmJsYtH374YQ0fPlytWrVSnz593LZffvlFycnJ+vTTT0NTUgAAAAAAomHKsJ49e2rBggV6+eWXNXfuXLftrLPO0jnnnKOUlJSqLiO88ttbUn6u1OEwqU4zr0sDAAAAANEzT3dqaqobXA0R7Ov/k9b/IZ37NkE3AAAAAIQy6H7//ffdaOUJCQnu/q4cf/zxlSkLwonPxxzdAAAAAFBdQfeJJ56oNWvWuBHK7f6u+n3n5eXtbbngtYwNUo6NRB8jpbX2ujQAAAAAENlBd35+fpn3EaECWe46zaX4JK9LAwAAAACRPWXY7qSnp1fVoRBOQXd9mpYDAAAAQLUG3Q888IBef/31wvXTTjtNDRo0UMuWLd3UYYgAm+nPDQAAAACeBN1PPfWUWrf29/OdNGmSPv/8c02cONENtHbDDTfsdaEQBsh0AwAAAIA3U4bZgGqBoPvDDz/U6aefrmHDhqldu3YaNGjQ3pcK3jv4OqnrsWS6AQAAAKC6M93169fXihUr3H3LcA8ZMsTd9/l8jFweKdLaSJ2HSo338bokAAAAABBdme6TTz5ZZ599tjp37qyNGze6ZuXm559/VqdOnaq6jAAAAAAARE/Q/e9//9s1Jbds9z//+U/Vrl3bbV+9erUuv/zyqi4jqlvGRunH8VLDDlLPU7wuDQAAAABEV9CdkJCg66+/vtT2a665pirKBK9tmCd9eY+/PzdBNwAAAACEPuh+//33XTNyC7jt/q4cf/zxlS8Rwme6MEYuBwAAAIDqCbpPPPFEN2p5kyZN3P3yxMTEMJhaTZe+3L9k5HIAAAAAqJ6gOz8/v8z7iEDM0Q0AAAAA3k0ZhihpXk6mGwAAAACqP+i+8sor9cgjj5Ta/thjj+nqq6/euxIhfDLdBN0AAAAAUP1B94QJE3TggQeW2n7AAQforbfe2rsSwVt5OdLWlf77NC8HAAAAgOqfMmzjxo2qV69eqe1169bVhg0b9q5E8FZMnHT59/4m5rWaeF0aAAAAAIi+THenTp00ceLEUts/+eQTdejQYY+P9/jjj6tdu3ZKTk7WoEGDNGPGjHL3zcnJ0V133aWOHTu6/fv06VOqLPfff7/2228/1alTp3C09Xnz5u1xuaJSbKzUuIu0zzD/fQAAAABA9Wa6r732Wo0ePVrr16/XEUcc4bZNnjxZDz74oMaNG7dHx3r99dfd8Z566ikXcNvzhw8f7oJkC5hLuu222/TSSy/p2WefVdeuXfXpp5/qpJNO0nfffad+/fq5fb766itdccUVLvDOzc3VLbfcomHDhmnOnDmqVatWZd4yAAAAAADVE3RfdNFF2rlzp+69917dfffdbptlqp988kmdf/75e3Sshx56SKNGjdKFF17o1i34/uijjzR+/HjddNNNpfZ/8cUXdeutt2rEiBFu/bLLLtPnn3/uAn4Lxk3JzPfzzz/vAviZM2fqkEMOqcxbjh5/fCit/0PqeITUsr/XpQEAAACA6Au6A8Gu3SzbnZKSotq1a+/xMbKzs10gfPPNNxdui42N1ZAhQzRt2rQyn2PBvjUrD2avP3Xq1HJfZ8uWLW7ZoEGDco9pt4CtW7cWNmW3W7gKlK0qyxg3+23F/j5BeYpTfpPeVXZcRHa9QXSg7qAyqDeoLOoOKou6g+qqNxXdN8bn8/kqUyhrtj1lyhQtWrRIZ599tus/vWrVKjeYWkUDcNu/ZcuWrmn44MGDC7ffeOONron49OnTSz3HXuuXX37Ru+++6/p1W7P2E044QXl5ecUC54D8/Hwdf/zxSk9PLzcwv/POOzV27NhS21955RWlpqYqmhw8/y41yFioH9qN1qr6A70uDgAAAACEpczMTBefWpLX4uAqzXQvW7ZMRx11lJYvX+4C3aFDh7qg+4EHHnDr1kQ8VB5++GHXHN36c8fExLjA25qmW3P0sljf7tmzZ+8yE26ZdutXHpzpbt26tesHvquT5zW7sjJp0iR3/hMSEqrkmPHzr3fLfoefoL4t/H3kEVlCUW8QHag7qAzqDSqLuoPKou6guupNoIX07lQq6L7qqqs0YMAAl3Fu2LBh4XYb0MwC4opq1KiR4uLitHbt2mLbbb1Zs2ZlPqdx48Yuy52VleWmLmvRooXr+13WqOk22NuHH36or7/+Wq1atSq3HElJSe5Wkp3smvCHWmXlzNkhZaxzd+Mbd7ID7/0xEbZqSv1G+KHuoDKoN6gs6g4qi7qDUNebiu5XqTmhvvnmGzeKeGJiYrHtNpjaypUrK3wce37//v1dE/Hg5uC2HtzcvCzWr9uaplsz9wkTJrgm5gHWYt4C7nfeeUdffPGF2rdvv0fvL2qlL/cvE+tIKfW9Lg0AAAAA1HiVynRbYGx9qEv6888/XTPzPWHNukeOHOky5wMHDnRThmVkZBSOZm6joVtwbXNvG+vnbYF937593dL6Y1t5rB94cJNy64/93nvvufKsWbPGba9Xr54bdA27Cbrrt5ViYrwuDQAAAABEZ9BtfZ0tOH7mmWfcuvWt3r59u8aMGVM4lVdFnXHGGW4E9DvuuMMFxxZM25RfTZs2dY9bv3Eb0TzAmpVbln3x4sVuwDZ7PZtGLC0trXAfm7rMHHbYYcVe67nnntMFF1xQmbccHTYv9S/T2npdEgAAAACI3qD7//7v/9xAat27d3dBsI3YtmDBAtdH+9VXX93j41lTcLuVxUZID3booYdqzpw5uzxeJQdkR79zpXYHe10KAAAAAIjuoNtG9rZB1F5//XW3tCz3xRdfrHPOOYfm2zVZQorUpKvXpQAAAACA6A26bSh1m67LRgW3INtuAAAAAACgCkYvt2HRrUk5ItAnf5e+/j8pa4vXJQEAAACAiFCpKcNsdPAHHnjATdeFCJG1VZr+lPTF3VJMpaoFAAAAAKAq+nT/8MMPbi7tzz77TL169VKtWrWKPf72229X5rDwUvoy/zKlgZS0Z9O+AQAAAACqMOi26blOOeWUyjwVNWGObgAAAABA9Qfd+fn5+te//qX58+crOztbRxxxhO68805GLI8Emwsy3czRDQAAAABVZo86795777265ZZbVLt2bbVs2VKPPPKI69+NCGpeTqYbAAAAALwJuv/3v//piSee0Keffqp3331XH3zwgV5++WWXAUekZLrbeF0SAAAAAIjOoHv58uUaMWJE4fqQIUMUExOjVatWhaJs8CLTndbO65IAAAAAQHT26bYpwpKTk0vN252Tk1PV5UJ1u3iStGWFVK+V1yUBAAAAgOgMun0+ny644AIlJSUVbsvKytKll15abNowpgyrgZJqS026eV0KAAAAAIjeoHvkyJGltp177rlVWR4AAAAAAKIz6H7uuedCVxJ4Z+lU6dc3pLYHSn3O8Lo0AAAAABCdA6khQv35g/TTC9KiyV6XBAAAAAAiCkE3gqYLY45uAAAAAKhKBN0Imi6MOboBAAAAoCoRdENKX+5f1ifTDQAAAABViaA72uXnFwXdNC8HAAAAgCpF0B3ttq+R8rKlmDipbkuvSwMAAAAAEYWgO9pt+dO/rNdSitujGeQAAAAAALtBlBXtWg+Ubl4pZW70uiQAAAAAEHEIuiEl1fbfAAAAAABViublAAAAAACECJnuaPfZ7dLOrdKgS6Um3bwuDQAAAABEFDLd0e73d6WZz0tZW7wuCQAAAABEHILuaJaXK21d6b/PHN0AAAAAUOUIuqPZ1j8lX54UlyTVbup1aQAAAAAg4hB0R7PNy/zLtNZSLFUBAAAAAKoakVY0Sw8E3TQtBwAAAIBQIOiOZunL/cv6BN0AAAAAEAoE3dEsY71/SaYbAAAAAEKCebqj2XEPS8PukXw+r0sCAAAAABGJoDvaJdXxugQAAAAAELFoXg4AAAAAQIgQdEerTUukF0+SPr3V65IAAAAAQMSieXm02rhIWvSFtG2t1yUBAAAAgIhFpjtapS/1L5kuDAAAAABChqA7Wm1e5l8yXRgAAAAAhAxBd7RKDwTdbbwuCQAAAABELILuaM9007wcAAAAAEKGoFvRnukm6AYAAACAUCHojkbZmUX3yXQDAAAAQGQH3Y8//rjatWun5ORkDRo0SDNmzCh335ycHN11113q2LGj279Pnz6aOHHiXh0z6iSmSn9fKt38p5RUx+vSAAAAAEDE8jzofv3113XttddqzJgx+umnn1wQPXz4cK1bt67M/W+77TY9/fTTevTRRzVnzhxdeumlOumkk/Tzzz9X+phRi4AbAAAAACI76H7ooYc0atQoXXjhherevbueeuoppaamavz48WXu/+KLL+qWW27RiBEj1KFDB1122WXu/oMPPljpYwIAAAAAEArx8lB2drZmzpypm2++uXBbbGyshgwZomnTppX5nJ07d7om48FSUlI0derUvTqm3QK2bt1a2JTdbuEqULY9LWPsdw8rZtm3yu93vnxdjw1R6RBp9Qag7qAyqDeoLOoOKou6g+qqNxXd19Oge8OGDcrLy1PTpk2Lbbf1uXPnlvkcayZumexDDjnE9euePHmy3n77bXecyh7z/vvv19ixY0tt/+yzz1yGPNxNmjRpj/YfuPhDNd/ys37Lbq2liz1v7IAaUm+AAOoOKoN6g8qi7qCyqDsIdb3JzAwaoDpcg+7KePjhh13T8a5duyomJsYF3taMfG+ajltW3PqAB2e6W7durWHDhqlu3boKV3ZlxSrF0KFDlZCQUOHnxT/7D7fsceDR6t5pSAhLiEiqNwB1B5VBvUFlUXdQWdQdVFe9CbSQDuugu1GjRoqLi9PatWuLbbf1Zs2alfmcxo0b691331VWVpY2btyoFi1a6KabbnL9uyt7zKSkJHcryU52TfhD3aNy+nxS+nJ3N75RR3tyaAuHsFVT6jfCD3UHlUG9QWVRd1BZ1B2Eut5UdD9P2xYnJiaqf//+rol4QH5+vlsfPHjwLp9r/bpbtmyp3NxcTZgwQSeccMJeHzMqZG6Ssrf776e18bo0AAAAABDRPG9ebs26R44cqQEDBmjgwIEaN26cMjIyXJNxc/7557vg2vpdm+nTp2vlypXq27evW955550uqL7xxhsrfMyolr7Mv6zdTEooPiAdAAAAACDCgu4zzjhD69ev1x133KE1a9a4YHrixImFA6EtX77cjT4eYM3Kba7uxYsXq3bt2m66MJtGLC0trcLHjGqBoLt+W69LAgAAAAARz/Og24wePdrdyjJlypRi64ceeqjmzJmzV8eMatmZUnKalEbQDQAAAABREXSjGvU7x3/LY95CAAAAAAg1JmmOVnGM5AgAAAAAoUbQDQAAAABAiBB0R5P8fOnJA6WXTvFPHQYAAAAACCn6dEeT7WultbOldXOkpDpelwYAAAAAIh6Z7miSvty/rNuKPt0AAAAAUA0IuqMJc3QDAAAAQLUi6I4mmwuCbuboBgAAAIBqQdAdTdKX+pdpbbwuCQAAAABEBYLuaMx007wcAAAAAKoFQXc0SawtJafRvBwAAAAAqglThkWTs1/zL30+r0sCAAAAAFGBTHc0ionxugQAAAAAEBUIugEAAAAACBGC7mjx6xvSY/tJX9zjdUkAAAAAIGoQdEeLDQukDfOljA1elwQAAAAAogZBd7RIZ7owAAAAAKhuBN3RNkd3WhuvSwIAAAAAUYOgO9oy3WntvC4JAAAAAEQNgu5okJMlbVvtv0/zcgAAAACoNgTd0WDLn/5lQi0ptaHXpQEAAACAqBHvdQFQDXIypWa9pcRaUkyM16UBAAAAgKhB0B0NmveWLv3G61IAAAAAQNSheTkAAAAAACFC0A0AAAAAQIgQdEeD54+VHhsorZjhdUkAAAAAIKrQpzsarJsjZW6U4pO9LgkAAAAARBUy3ZFu53Z/wG2YoxsAAAAAqhVBd6RLX+5fJqdJyfW8Lg0AAAAARBWC7kiXvsy/JMsNAAAAANWOoDvSbS4IutMIugEAAACguhF0R0umO62N1yUBAAAAgKhD0B3pajWWmvaSGnf1uiQAAAAAEHWYMizSHXyt/wYAAAAAqHZkugEAAAAACBGC7kjm8/lvAAAAAABPEHRHstWzpPtaSM8f63VJAAAAACAqEXRH+nRhOZlS7k6vSwIAAAAAUYmgO5IxXRgAAAAAeIqgO5KlL/cv67f1uiQAAAAAEJUIuiO9eblJI+gGAAAAAC8QdEdD83Iy3QAAAADgCYLuSGVThQWal9OnGwAAAACiM+h+/PHH1a5dOyUnJ2vQoEGaMWPGLvcfN26cunTpopSUFLVu3VrXXHONsrKyCh/Py8vT7bffrvbt27t9OnbsqLvvvlu+aJuv2kYt73ik1LSXVLeV16UBAAAAgKgU7+WLv/7667r22mv11FNPuYDbAurhw4dr3rx5atKkSan9X3nlFd10000aP368DjjgAM2fP18XXHCBYmJi9NBDD7l9HnjgAT355JN64YUX1KNHD/3444+68MILVa9ePV155ZWKGom1pLNe8boUAAAAABDVPM10W6A8atQoFxR3797dBd+pqakuqC7Ld999pwMPPFBnn322y44PGzZMZ511VrHsuO1zwgkn6JhjjnH7nHrqqW6/3WXQAQAAAACImKA7OztbM2fO1JAhQ4oKExvr1qdNm1bmcyy7bc8JBNCLFy/Wxx9/rBEjRhTbZ/LkyS4Lbn755RdNnTpVRx99tKJKTpa/XzcAAAAAIPqal2/YsMH1v27atGmx7bY+d+7cMp9jGW573kEHHeT6aOfm5urSSy/VLbfcUriPNT/funWrunbtqri4OPca9957r84555xyy7Jz5053C7Dnm5ycHHcLV4GylVXGuA+vVcycd5V/xB3KH3CxB6VDTaw3wK5Qd1AZ1BtUFnUHlUXdQXXVm4ru62mf7j01ZcoU3XfffXriiSdcH/CFCxfqqquucgOl2eBp5o033tDLL7/s+n9bn+5Zs2bp6quvVosWLTRy5Mgyj3v//fdr7NixpbZ/9tlnrrl7uJs0aVKpbQcs+lmNczL0yx+LtGLdx56UCzWv3gAVQd1BZVBvUFnUHVQWdQehrjeZmZkV2i/G59Gw3ta83ALat956SyeeeGLhdguM09PT9d5775V6zsEHH6z9999f//rXvwq3vfTSS7rkkku0fft21zzdRjS3bPcVV1xRuM8999zj9isvg15WptuOY1n1unXrKlzZlRWrFEOHDlVCQkKxx+IfH6CY9KXKPe8D+doM9qyMqFn1BtgV6g4qg3qDyqLuoLKoO6iuemNxY6NGjbRly5Zdxo2eZboTExPVv39/1/86EHTn5+e79dGjR5d7JcEC62DWhNwErh2Ut48duzxJSUnuVpKd7Jrwh1qqnPl50tY/3d34Rh1tB+8Kh7BVU+o3wg91B5VBvUFlUXdQWdQdhLreVHQ/T5uX23RhltkeMGCABg4c6KYMy8jIcKOZm/PPP18tW7Z0zb/Ncccd50Y879evX2HzcmtWbtsDwbfdtz7cbdq0cc3Lf/75Z/eciy66SFFj60opP1eKTZDqNPO6NAAAAAAQtTwNus844wytX79ed9xxh9asWaO+fftq4sSJhYOrLV++vFjW+rbbbnNzctty5cqVaty4cWGQHfDoo4+6QPzyyy/XunXrXF/uv/71r+41okb6cv8yrbUU678YAQAAAACofp4PpGZNyctrTm4DpwWLj4/XmDFj3K08derUcRlzu0Wtzcv8y7S2XpcEAAAAAKKa50E3QqB2E6nLMVKLfl6XBAAAAACiGkF3JOo81H8DAAAAAHiq+DDfAAAAAACgyhB0R6LMTTaHmtelAAAAAICoR9AdaXJ3Sv/sIN3fyh98AwAAAAA8Q9AdadJXSPJJvnwppb7XpQEAAACAqEbQHWnSg6YLi4nxujQAAAAAENUIuiM16K7PHN0AAAAA4DWC7kizOZDpbuN1SQAAAAAg6hF0R3LzcgAAAACApwi6IzXTTfNyAAAAAPBcvNcFQBXrNESq00xq1MXrkgAAAABA1CPojjRH3Op1CQAAAAAABWheDgAAAABAiBB0R5KsLVLmJsnn87okAAAAAACC7gjzy2vSP9tLE/7idUkAAAAAAATdETpyuQ2kBgAAAADwHEF3JGGObgAAAAAIKwTdkYQ5ugEAAAAgrBB0RwobPI1MNwAAAACEFYLuSJGVLu3c6r+f1sbr0gAAAAAACLojsGl5rSZSYqrXpQEAAAAASIr3ugCoIkl1pIF/leISvC4JAAAAAKAAQXekaNhRGvFPr0sBAAAAAAhC83IAAAAAAEKEoDtSbFwkZW7yj2IOAAAAAAgLBN2R4tWzpH+2lxZP8bokAAAAAIACBN0RM0f3cv99pgsDAAAAgLBB0B0JMtZLuTskxUj1WntdGgAAAABAAYLuCBCzpSDLXbelFJ/odXEAAAAAAAUIuiNB+jL/sn5br0sCAAAAAAhC0B0BYujPDQAAAABhiaA7AsQEMt1pZLoBAAAAIJzEe10A7L38jkcqNjFVajvY66IAAAAAAIIQdEcAX9fjpF4ne10MAAAAAEAJNC8HAAAAACBECLpruLi8LGn1LClzk9dFAQAAAACUQNBdw6XtWKqE8UOkZ4/wuigAAAAAgBIIumu41J3r/XeYoxsAAAAAwg5Bdw2Xml0QdDNdGAAAAACEHYLuiAm623hdFAAAAABACQTdNVzqzg3+O/XbeV0UAAAAAEAJBN01XC2alwMAAABA2CLorsnyspWcs9l/n4HUAAAAACDseB50P/7442rXrp2Sk5M1aNAgzZgxY5f7jxs3Tl26dFFKSopat26ta665RllZWcX2Wblypc4991w1bNjQ7derVy/9+OOPijj5ufq9xZnK2+8SqVZjr0sDAAAAACghXh56/fXXde211+qpp55yAbcF1MOHD9e8efPUpEmTUvu/8soruummmzR+/HgdcMABmj9/vi644ALFxMTooYcecvts3rxZBx54oA4//HB98sknaty4sRYsWKD69esr4iSkalHTo9Vl2AjFxcR4XRoAAAAAQDgF3RYojxo1ShdeeKFbt+D7o48+ckG1Bdclfffddy6gPvvss926ZcjPOussTZ8+vXCfBx54wGXAn3vuucJt7du3r5b3AwAAAABAWATd2dnZmjlzpm6++ebCbbGxsRoyZIimTZtW5nMsu/3SSy+5JugDBw7U4sWL9fHHH+u8884r3Of999932fLTTjtNX331lVq2bKnLL7/cBffl2blzp7sFbN261S1zcnLcLVzlrp6teplLlbN9s1Q7AjP5CIlAnQ7nuo3wRN1BZVBvUFnUHVQWdQfVVW8quq9nQfeGDRuUl5enpk2bFttu63Pnzi3zOZbhtucddNBB8vl8ys3N1aWXXqpbbrmlcB8LxJ988knXbN22//DDD7ryyiuVmJiokSNHlnnc+++/X2PHji21/bPPPlNqaqrCVf8lT+iw9O81e9scLWo6wuvioIaZNGmS10VADUXdQWVQb1BZ1B1UFnUHoa43mZmZ4d+8fE9NmTJF9913n5544gnXB3zhwoW66qqrdPfdd+v22293++Tn52vAgAFuP9OvXz/Nnj3bNV0vL+i2bLsF6cGZbmuiPmzYMNWtW1fhKnb8OCld6rzfkerSk6AbFb8iZ18mQ4cOVUJCgtfFQQ1C3UFlUG9QWdQdVBZ1B9VVbwItpMM26G7UqJHi4uK0du3aYtttvVmzZmU+xwJra0r+l7/8xa3bqOQZGRm65JJLdOutt7rm6c2bN1f37t2LPa9bt26aMGFCuWVJSkpyt5LsZIfzH6pv6wq3jG3YIazLifAU7vUb4Yu6g8qg3qCyqDuoLOoOQl1vKrqfZ1OGWXPv/v37a/LkyYXbLEtt64MHDy43fW+BdTAL3I01Nzc20JqNfh7MRjlv2zbC5rHOzlRMxnr//bQIe28AAAAAECE8bV5uTbqtybc1B7eB0WzKMMtcB0YzP//8891AaNbn2hx33HFuxHNrMh5oXm7Zb9seCL5t3m4bcM2al59++ulu0LVnnnnG3SJK+nK3yIlLlVLSvC4NAAAAACDcgu4zzjhD69ev1x133KE1a9aob9++mjhxYuHgasuXLy+W2b7tttvcnNy2XLlypZuD2wLue++9t3Cf/fbbT++8847rp33XXXe56cIsmD/nnHMUUdKXuUVGYiPV8rosAAAAAIDwHEht9OjR7lbewGnB4uPjNWbMGHfblWOPPdbdItpmf9C9I7ExQTcAAAAAhCnPg25UUtsDlHfknVqxeKMaeV0WAAAAAECZCLprqmY9ld+wi1Zv+lj9vC4LAAAAACC8Ri8HAAAAACDSEXQDAAAAABAiBN0AAAAAAIQIQTcAAAAAACFC0A0AAAAAQIgQdAMAAAAAECIE3QAAAAAAhAhBNwAAAAAAIULQDQAAAABAiBB0AwAAAAAQIgTdAAAAAACECEE3AAAAAAAhQtANAAAAAECIEHQDAAAAABAiBN0AAAAAAIQIQTcAAAAAACESH6oD12Q+n88tt27dqnCWk5OjzMxMV86EhASvi4MagnqDyqLuoDKoN6gs6g4qi7qD6qo3gXgxED+Wh6C7DNu2bXPL1q1be10UAAAAAECYx4/16tUr9/EY3+7C8iiUn5+vVatWqU6dOoqJiVG4sisrdmFgxYoVqlu3rtfFQQ1BvUFlUXdQGdQbVBZ1B5VF3UF11RsLpS3gbtGihWJjy++5Taa7DHbCWrVqpZrCKgVfKNhT1BtUFnUHlUG9QWVRd1BZ1B1UR73ZVYY7gIHUAAAAAAAIEYJuAAAAAABChKC7BktKStKYMWPcEqgo6g0qi7qDyqDeoLKoO6gs6g7Crd4wkBoAAAAAACFCphsAAAAAgBAh6AYAAAAAIEQIugEAAAAACBGC7hrq8ccfV7t27ZScnKxBgwZpxowZXhcJYe7OO+9UTExMsVvXrl29LhbCzNdff63jjjtOLVq0cHXk3XffLfa4DQNyxx13qHnz5kpJSdGQIUO0YMECz8qLmlN3LrjgglLfQUcddZRn5UV4uP/++7XffvupTp06atKkiU488UTNmzev2D5ZWVm64oor1LBhQ9WuXVunnHKK1q5d61mZUXPqzmGHHVbqe+fSSy/1rMzw3pNPPqnevXsXzsU9ePBgffLJJyH/viHoroFef/11XXvttW50vZ9++kl9+vTR8OHDtW7dOq+LhjDXo0cPrV69uvA2depUr4uEMJORkeG+U+zCXln++c9/6pFHHtFTTz2l6dOnq1atWu77x/6TQnTbXd0xFmQHfwe9+uqr1VpGhJ+vvvrK/cD9/vvvNWnSJOXk5GjYsGGuPgVcc801+uCDD/Tmm2+6/VetWqWTTz7Z03KjZtQdM2rUqGLfO/b/GKJXq1at9I9//EMzZ87Ujz/+qCOOOEInnHCCfv/999B+39jo5ahZBg4c6LviiisK1/Py8nwtWrTw3X///Z6WC+FtzJgxvj59+nhdDNQg9l/EO++8U7ien5/va9asme9f//pX4bb09HRfUlKS79VXX/WolKgJdceMHDnSd8IJJ3hWJtQM69atc/Xnq6++KvyOSUhI8L355puF+/zxxx9un2nTpnlYUoR73TGHHnqo76qrrvK0XAh/9evX9/3nP/8J6fcNme4aJjs7212ZsSadAbGxsW592rRpnpYN4c+aAVvTzw4dOuicc87R8uXLvS4SapAlS5ZozZo1xb5/6tWr57q48P2DipgyZYprBtqlSxdddtll2rhxo9dFQpjZsmWLWzZo0MAt7TePZTCDv3esa1SbNm343sEu607Ayy+/rEaNGqlnz566+eablZmZ6VEJEW7y8vL02muvudYR1sw8lN838VVQXlSjDRs2uArStGnTYtttfe7cuZ6VC+HPAqPnn3/e/di15lVjx47VwQcfrNmzZ7v+UMDuWMBtyvr+CTwG7KppuTXRa9++vRYtWqRbbrlFRx99tPshExcX53XxEAby8/N19dVX68ADD3QBkrHvlsTERKWlpRXbl+8d7K7umLPPPltt27Z1CYdff/1Vf//7312/77ffftvT8sJbv/32mwuyrWuc9dt+55131L17d82aNStk3zcE3UCUsB+3ATaAhAXh9h/RG2+8oYsvvtjTsgGIfGeeeWbh/V69ernvoY4dO7rs95FHHulp2RAerH+uXQhmvBFUVd255JJLin3v2CCg9n1jF/7s+wfRqUuXLi7AttYRb731lkaOHOn6b4cSzctrGGseYxmBkqPo2XqzZs08KxdqHruKt88++2jhwoVeFwU1ROA7hu8fVAXr5mL/p/EdBDN69Gh9+OGH+vLLL91ARwH23WJd69LT04vtz/cOdld3ymIJB8P3TnRLTExUp06d1L9/fzcKvg0C+vDDD4f0+4aguwZWEqsgkydPLtakxtatmQRQUdu3b3dXeu2qL1AR1izY/tMJ/v7ZunWrG8Wc7x/sqT///NP16eY7KLrZuHsWNFnzzi+++MJ9zwSz3zwJCQnFvnesebCNScL3TnTbXd0pi2U3Dd87CGax1M6dO0P6fUPz8hrIpguzZhADBgzQwIEDNW7cODcAwIUXXuh10RDGrr/+ejeHrjUpt+kPbMo5azVx1llneV00hNnFmOAMgA2eZj9SbGAaG0jE+szdc8896ty5s/uBc/vtt7u+cjY/KqLbruqO3WwcCZvv1C7c2AW/G2+80WUabMo5RHez4FdeeUXvvfeeG18k0G/SBmlMSUlxS+sCZb99rB7ZvLp/+9vf3A/g/fff3+viI4zrjn3P2OMjRoxwcy5bn26bDuqQQw5x3VsQnW6++WbX5dJ+02zbts3VEevm9Omnn4b2+6YKRlmHBx599FFfmzZtfImJiW4Kse+//97rIiHMnXHGGb7mzZu7OtOyZUu3vnDhQq+LhTDz5ZdfuqkxSt5suqfAtGG33367r2nTpm6qsCOPPNI3b948r4uNMK87mZmZvmHDhvkaN27spmNp27atb9SoUb41a9Z4XWx4rKw6Y7fnnnuucJ8dO3b4Lr/8cjetT2pqqu+kk07yrV692tNyI/zrzvLly32HHHKIr0GDBu7/q06dOvluuOEG35YtW7wuOjx00UUXuf+D7Pew/Z9kv2M+++yzkH/fxNg/VXXlAAAAAAAAFKFPNwAAAAAAIULQDQAAAABAiBB0AwAAAAAQIgTdAAAAAACECEE3AAAAAAAhQtANAAAAAECIEHQDAAAAABAiBN0AAAAAAIQIQTcAAFHgqquu0iWXXKL8/HyviwIAQFQh6AYAIMKtWLFCXbp00dNPP63YWP7rBwCgOsX4fD5ftb4iAAAAAABRgsvdAABEqAsuuEAxMTGlbkcddZTXRQMAIGrEe10AAAAQOhZgP/fcc8W2JSUleVYeAACiDZluAAAimAXYzZo1K3arX7++e8yy3k8++aSOPvpopaSkqEOHDnrrrbeKPf+3337TEUcc4R5v2LChG4xt+/btxfYZP368evTo4V6refPmGj16dOFjDz30kHr16qVatWqpdevWuvzyy0s9HwCASEbQDQBAFLv99tt1yimn6JdfftE555yjM888U3/88Yd7LCMjQ8OHD3dB+g8//KA333xTn3/+ebGg2oL2K664wgXjFqC///776tSpU+HjNnDbI488ot9//10vvPCCvvjiC914442evFcAALzAQGoAAERwn+6XXnpJycnJxbbfcsst7maZ7ksvvdQFzgH777+/9t13Xz3xxBN69tln9fe//92Nfm6ZavPxxx/ruOOO06pVq9S0aVO1bNlSF154oe65554Klcky6faaGzZsqOJ3CwBAeKJPNwAAEezwww8vFlSbBg0aFN4fPHhwscdsfdasWe6+Zbz79OlTGHCbAw880M31PW/ePBe0W/B95JFHlvv6lhm///77NXfuXG3dulW5ubnKyspSZmamUlNTq/CdAgAQnmheDgBABLOA2Zp7B9+Cg+69Yf28d2Xp0qU69thj1bt3b02YMEEzZ87U448/7h7Lzs6ukjIAABDuCLoBAIhi33//fan1bt26ufu2tL7e1rc74Ntvv3X9tLt06aI6deqoXbt2mjx5cpnHtiDbsuIPPviga7a+zz77uMw4AADRhOblAABEsJ07d2rNmjXFtsXHx6tRo0buvg2ONmDAAB100EF6+eWXNWPGDP33v/91j9nAamPGjNHIkSN15513av369frb3/6m8847z/XnNrbd+mg3adLEjYK+bds2F5jbfpZVz8nJ0aOPPur6gdv2p556yoOzAACAd8h0AwAQwSZOnOim8Qq+WYAdMHbsWL322muuCfj//vc/vfrqq+revbt7zPpcf/rpp9q0aZP2228/nXrqqa7/9mOPPVb4fAvIx40b5wZes2nDrDn5ggUL3GPWH9ymDHvggQfUs2dPF9Rb/24AAKIJo5cDABClbCC0d955RyeeeKLXRQEAIGKR6QYAAAAAIEQIugEAAAAACBEGUgMAIErRwwwAgNAj0w0AAAAAQIgQdAMAAAAAECIE3QAAAAAAhAhBNwAAAAAAIULQDQAAAABAiBB0AwAAAAAQIgTdAAAAAACECEE3AAAAAAAhQtANAAAAAIBC4/8Bux+vkn4Ji7MAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Gráfica de precisión en validación\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history_final.history['val_accuracy'], label='Precisión en validación', marker='o')\n",
    "plt.plot(history_final.history['accuracy'], label='Precisión en entrenamiento', linestyle='--')\n",
    "plt.title('Precisión por época')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Precisión')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
